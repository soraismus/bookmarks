[Learning as You Go](http://tomhopper.me/)
==========================================

Lessons in new product development, R&D, science and technology.
----------------------------------------------------------------

Menu

Search

[Skip to content](#content)

-   [Home](http://tomhopper.me/)
-   [About](http://tomhopper.me/about/)
-   [Hypotheses](http://tomhopper.me/hypotheses/)

Search for:

Can We do Better than R-squared?
================================

If you're anything like me, you've used Excel to plot data, then used
the built-in “add fitted line” feature to overlay a fitted line to show
the trend, and displayed the “goodness of fit,” the r-squared (*R*^2^)
value, on the chart by checking the provided box in the chart dialog.

The *R*^2^ calculated in Excel is often used as a measure of how well a
model explains a response variable, so that “*R*^2^ = 0.8” is
interpreted as “80% of the variation in the 'y' variable is explained by
my model.” I think that the ease with which the *R^2^* value can be
calculated and added to a plot is one of the reasons for its popularity.

There's a hidden trap, though. *R*^2^ will increase as you add terms to
a model, even if those terms offer no real explanatory power. By using
the *R*^2^ that Excel so helpfully provides, we can fool ourselves into
believing that a model is better than it is.

Below I'll demonstrate this and show an alternative that can be
implemented easily in [R](http://www.r-project.org).

### Some data to work with

First, let's create a simple, random data set, with factors *a*, *b*,
*c* and response variable *y*.

~~~~ {.brush: .r; .title: .; .notranslate title=""}
head(my.df)
~~~~

~~~~ {.brush: .plain; .light: .true; .title: .; .notranslate title=""}
##       y a       b      c
## 1 2.189 1 -1.2935 -0.126
## 2 3.912 2 -0.4662  1.623
## 3 4.886 3  0.1338  2.865
## 4 5.121 4  1.2945  4.692
## 5 4.917 5  0.1178  5.102
## 6 4.745 6  0.4045  5.936
~~~~

Here is what this data looks like:

[![Plot of the response and factors in a linear
model.](http://tomhopper.files.wordpress.com/2014/05/model_plot.png?w=646&h=430)](http://tomhopper.files.wordpress.com/2014/05/model_plot.png)

### Calculating R-squared

What Excel does when it displays the *R*^2^ is create a linear
least-squares model, which in R looks something like:

~~~~ {.brush: .r; .title: .; .notranslate title=""}
my.lm <- lm(y ~ a + b + c, data = my.df)
~~~~

Excel also does this when we call `RSQ()` in a worksheet. In fact, we
can do this explicitly in Excel using the Regression analysis option in
the Analysis Pack add-on, but I don't know many people who use this, and
Excel isn't known for its reliability in producing good output from the
Analysis Pack.

In R, we can obtain *R*^2^ via the `summary()` function on a linear
model.

~~~~ {.brush: .r; .title: .; .notranslate title=""}
summary(my.lm)
~~~~

~~~~ {.brush: .plain; .light: .true; .title: .; .notranslate title=""}
## 
## Call:
## lm(formula = y ~ a + b + c, data = my.df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.2790 -0.6006  0.0473  0.5177  1.5299 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)    2.080      0.763    2.72    0.034 *
## a             -0.337      0.776   -0.43    0.679  
## b             -0.489      0.707   -0.69    0.515  
## c              1.038      0.817    1.27    0.250  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.1 on 6 degrees of freedom
## Multiple R-squared:  0.833,  Adjusted R-squared:  0.75 
## F-statistic:   10 on 3 and 6 DF,  p-value: 0.00948
~~~~

Since `summary()` produces a *list* object as output, we can grab just
the *R*^2^ value.

~~~~ {.brush: .r; .title: .; .notranslate title=""}
summary(my.lm)$r.squared
~~~~

~~~~ {.brush: .plain; .light: .true; .title: .; .notranslate title=""}
## [1] 0.8333
~~~~

Normally, we would (somewhat loosely) interpret this as telling us that
about 83% of the variation in the response *y* is explained by the
model.

Notice that there is also an "adjusted r-squared” value given by
`summary()`. This tells us that only 75% of the variation is explained
by the model. Which is right?

### The problem with R-squared

Models that have many terms will always give higher *R*^2^ values, just
because more terms will slightly improve the model fit to the given
data. The unadjusted *R*^2^ is wrong. The calculation for adjusted
*R*^2^ is intended to partially compensate for that “overfit,” so it's
better.

It's nice that R shows us both values, and a pity that Excel won't show
the adjusted value. The only way to get an adjusted *R*^2^ in Excel is
to run the Regression analysis; otherwise, we have to calculate adjusted
*R*^2^ manually.

Both *R*^2^ and adjusted *R*^2^ are measures of how well the model
explains the *given* data. However, in industry we usually want to know
something a little different. We don't build regression models to
explain only the data we have; we build them to think about future
results. We want *R*^2^ to tell us how well the model predicts the
future. That is, we want a *predictive* *R*^2^. Minitab has added the
ability to calculate predictive *R*^2^ in Minitab 17, and has a nice
blog post [explaining this
statistic](http://blog.minitab.com/blog/adventures-in-statistics/multiple-regession-analysis-use-adjusted-r-squared-and-predicted-r-squared-to-include-the-correct-number-of-variables).

### Calcuting predictive R-squared

Neither R nor Excel provide a means of calculating the predictive *R*^2^
within the default functions. While some free R add-on packages provide
this ability (DAAG, at least), we can easily do it ourselves. We'll need
a linear model, created with `lm()`, for the residuals so we can
calculate the “PRESS” statistic, and then we need the sum of squares of
the terms so we can calculate a predictive *R*^2^.

Since the predictive *R*^2^ depends entirely on the PRESS statistic, we
could skip the added work of calculating predictive *R*^2^ and just use
PRESS, [as some authors
advocate](http://www.analyticbridge.com/profiles/blogs/use-press-not-r-squared-to-judge-predictive-power-of-regression).
The lower the PRESS, the better the model is at fitting future data from
the same process, so we can use PRESS to compare different models.
Personally, I'm used to thinking in terms of *R*^2^, and I like having
the ability to compare to the old *R*^2^ statistic that I'm familiar
with.

To calculate PRESS, first we calculate the predictive residuals, then
take the sum of squares (thanks to ([Walker’s helpful blog
post](http://stevencarlislewalker.wordpress.com/2013/06/18/calculating-the-press-statistic-in-r/))
for this). This is pretty easy if we already have a linear model. It
would take a little more work in Excel.

~~~~ {.brush: .r; .title: .; .notranslate title=""}
pr <- residuals(my.lm)/(1 - lm.influence(my.lm)$hat)
PRESS <- sum(pr^2)
PRESS
~~~~

~~~~ {.brush: .plain; .light: .true; .title: .; .notranslate title=""}
## [1] 19.9
~~~~

The predictive *R*^2^ is then (from a helpful [comment by
Ibanescu](http://www.linkedin.com/groups/Adjusted-RSquare-Predicted-RSquare-3696237.S.77951329)
on LikedIn) the PRESS divided by the total sum of squares, subtracted
from one. The total sum of squares can be calculated directly as the sum
of the squared residuals, or obtained by summing over *Sum Sq* from an
`anova()` on our linear model. I prefer using the anova function, as any
statistical subtleties are more likely to be properly accounted for
there than in my simple code.

~~~~ {.brush: .r; .title: .; .notranslate title=""}
# anova to calculate residual sum of squares
my.anova <- anova(my.lm)
tss <- sum(my.anova$"Sum Sq")
# predictive R^2
pred.r.squared <- 1 - PRESS/(tss)
pred.r.squared
~~~~

~~~~ {.brush: .plain; .light: .true; .title: .; .notranslate title=""}
## [1] 0.5401
~~~~

You'll notice that this is smaller than the residual *R*^2^, which is
itself smaller than the basic *R*^2^. This is the point of the exercise.
We don't want to fool ourselves into thinking we have a better model
than we actually do. One way to think of this is that 29% (83% – 54%) of
the model is explained by too many factors and random correlations,
which we would have attributed to our model if we were just using
Excel's built-in function.

When the model is good and has few terms, the differences are small. For
example, working through the examples in Mitsa's two posts, we see that
for her model 3, *R*^2^ = 0.96 and the predictive *R*^2^ = 0.94, so
calculating the predictive *R*^2^ wasn't really worth the extra effort
for that model. Unfortunately, we can't know, in advance, which models
are “good.” For Mitsa's model 1 we have *R*^2^ = 0.95 and predictive
*R*^2^ = 0.32. Even the adjusted *R*^2^ looks pretty good for model 1,
at 0.94, but we see from the predictive *R*^2^ that our model is not
very useful. This is the sort of thing we need to know to make correct
decisions.

### Automating

In R, we can easily wrap these in functions that we can `source()` and
call directly, reducing the typing. Just create a linear model with
`lm()` (or an equivalent) and pass that to either function. Note that
`pred_r_squared()` calls `PRESS()`, so both functions have to be
sourced.

~~~~ {.brush: .r; .title: .; .notranslate title=""}
pred_r_squared <- function(linear.model) {
    lm.anova <- anova(linear.model)
    tss <- sum(lm.anova$"Sum Sq")
    # predictive R^2
    pred.r.squared <- 1 - PRESS(linear.model)/(tss)
    return(pred.r.squared)
}
~~~~

~~~~ {.brush: .r; .title: .; .notranslate title=""}
PRESS <- function(linear.model) {
    pr <- residuals(linear.model)/(1 - lm.influence(linear.model)$hat)
    PRESS <- sum(pr^2)
    return(PRESS)
}
~~~~

Then we just call the function to get the result:

~~~~ {.brush: .r; .title: .; .notranslate title=""}
pred.r.squared <- pred_r_squared(my.lm)
pred.r.squared
~~~~

~~~~ {.brush: .plain; .light: .true; .title: .; .notranslate title=""}
## [1] 0.5401
~~~~

I've posted these as [Gists on
GitHub](https://gist.github.com/tomhopper/8c204d978c4a0cbcb8c0), with
extra comments, so you can copy and paste from here or go branch or copy
them there.

### References and further reading

-   Mitsa, T. [Use PRESS, not R squared to judge predictive power of
    regression](http://www.analyticbridge.com/profiles/blogs/use-press-not-r-squared-to-judge-predictive-power-of-regression).
    12 May 2013. Analytical Bridge. Accessed 14 May 2014. Shows how
    r-squared can lead to a misleading interpretation of model fit and
    provides an explanation of the PRESS statistic, with examples
    comparing three linear models in R.
-   Mitsa, T. [Cross-validation in R: a do-it-yourself and a black box
    approach](http://www.analyticbridge.com/profiles/blogs/cross-validation-in-r-a-do-it-yourself-and-a-black-box-approach?xg_source=activity).
    22 May 2013. Accessed 14 May 2014. Shows how to use the package DAAG
    to calculate PRESS, or to calculate it manually.
-   Walker, S. [Calculating the PRESS statistic in
    R](http://stevencarlislewalker.wordpress.com/2013/06/18/calculating-the-press-statistic-in-r/).
    18 June 2013. ecology & stats. Accessed 14 May 2014. Provides a
    simple function for calculating PRESS in R.
-   [Multiple Regression Analysis: Use Adjusted R-Squared and Predicted
    R-Squared to Include the Correct Number of
    Variables](http://blog.minitab.com/blog/adventures-in-statistics/multiple-regession-analysis-use-adjusted-r-squared-and-predicted-r-squared-to-include-the-correct-number-of-variables)
-   [Adjusted R-Square or Predicted
    R-Square](http://www.linkedin.com/groups/Adjusted-RSquare-Predicted-RSquare-3696237.S.77951329).
    LinkedIn. Accessed 14 May 2014. Forum dscussion thread discusing the
    relative merits of adjusted and predicted *R*^2^, in which the
    equation for calculating predicted *R*^2^ is given.
-   [Why is adjusted R-squared less than R-squared if adjusted R-squared
    predicts the model
    better?](http://stats.stackexchange.com/questions/52517/why-is-adjusted-r-squared-less-than-r-squared-if-adjusted-r-squared-predicts-the).
    StackExchange. Accessed 10 May 2014. Q&A thread discussing the
    relative merits of *R*^2^ and adjusted *R*^2^.
-   R Core Team (2014). *R: A language and environment for statistical
    computing.* R Foundation for\
     Statistical Computing, Vienna, Austria. URL
    [http://www.R-project.org/](http://www.R-project.org/).
-   H. Wickham. *ggplot2: elegant graphics for data analysis.* Springer
    New York, 2009.

[About these ads](http://en.wordpress.com/about-these-ads/)

### Share this:

-   [Email](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/?share=email "Click to email this to a friend")
-   [Twitter](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/?share=twitter "Click to share on Twitter")
-   [Google](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/?share=google-plus-1 "Click to share on Google+")
-   [Facebook](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/?share=facebook "Share on Facebook")
-   [LinkedIn](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/?share=linkedin "Click to share on LinkedIn")
-   [Tumblr](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/?share=tumblr "Click to share on Tumblr")
-   [StumbleUpon](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/?share=stumbleupon "Click to share on StumbleUpon")
-   [Digg](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/?share=digg "Click to Digg this post")
-   [Reddit](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/?share=reddit "Click to share on Reddit")
-   [Pocket](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/?share=pocket "Click to share on Pocket")
-   [Print](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/#print "Click to print")
-   

### Like this:

Like Loading...

### *Related*

[May 16,
2014](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/ "9:00 am")[Thomas
Hopper](http://tomhopper.me/author/tomhopper/ "View all posts by Thomas Hopper")
[rstats](http://tomhopper.me/tag/rstats/)

Post navigation
===============

[←](http://tomhopper.me/2014/04/25/combining-the-voice-of-the-customer-with-the-voice-of-the-process/)

[→](http://tomhopper.me/2014/05/23/flowing-requirements-from-the-voc-or-vop/)

6 thoughts on “Can We do Better than R-squared?”
------------------------------------------------

1.  ![image](http://1.gravatar.com/avatar/d55aa53e10e1817c8cbc6c8e475e5ad1?s=80&d=identicon&r=G)
    [stevencarlislewalker](http://stevencarlislewalker.wordpress.com)
    says:

    Really great post, thanks! You might be interested in a new R
    package I’m development that uses the bootstrap to estimate a
    distribution of predictive R\^2 statistics. To speed up the
    bootstrap, I’ve used C++ via Rcpp.

    [https://github.com/stevencarlislewalker/bootR2](https://github.com/stevencarlislewalker/bootR2)

    [Reply](/2014/05/16/can-we-do-better-than-r-squared/?replytocom=143#respond)

    [May 16, 2014 at 12:14
    pm](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/#comment-143)

    -   ![image](http://2.gravatar.com/avatar/2f544230bd672af485ae719a9dfdaaf5?s=80&d=identicon&r=G)
        [Thomas Hopper](http://tomhopper.wordpress.com/) says:

        Steve, thank you. That sounds like a great package; I’ll
        definitely have a look.

        [Reply](/2014/05/16/can-we-do-better-than-r-squared/?replytocom=144#respond)

        [May 16, 2014 at 2:34
        pm](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/#comment-144)

2.  Pingback: [Can We do Better than R-squared? ← Patient 2
    Earn](http://patient2earn.com/can-we-do-better-than-r-squared/)
3.  Pingback: [O tal R ao quadrado… | De Gustibus Non Est
    Disputandum](http://gustibusgustibus.wordpress.com/2014/05/17/o-tal-r-ao-quadrado/)
4.  ![image](http://0.gravatar.com/avatar/3f97aeed46268de2e3a2400a2b044a3b?s=80&d=identicon&r=G)
    [Gabriel Rega](http://gabrielkerr.wordpress.com) says:

    Reblogged this on [Gabriel
    Rega](http://gabrielrega.com/2014/05/19/can-we-do-better-than-r-squared/).

    [Reply](/2014/05/16/can-we-do-better-than-r-squared/?replytocom=147#respond)

    [May 19, 2014 at 3:01
    pm](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/#comment-147)

5.  ![image](http://1.gravatar.com/avatar/7ae4d003fbfd1f812dc5d3ba81319b53?s=80&d=identicon&r=G)
    [anspiess](http://rmazing.wordpress.com) says:

    Important article! Not wanting to do self-advertising ;-), but check
    the PRESS function in my ‘qpcR’ package that also works on nonlinear
    models where the “R-square” problem is even more severe,,,

    Cheers,\
     Andrej

    [Reply](/2014/05/16/can-we-do-better-than-r-squared/?replytocom=148#respond)

    [May 20, 2014 at 8:35
    am](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/#comment-148)

### Leave a Reply [Cancel reply](/2014/05/16/can-we-do-better-than-r-squared/#respond)

Enter your comment here...

Please log in using one of these methods to post your comment:

-   [](#comment-form-load-service:WordPress.com "WordPress.com")
-   [](#comment-form-load-service:Twitter "Twitter")
-   [](#comment-form-load-service:Facebook "Facebook")
-   

[![Gravatar](http://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&d=identicon&forcedefault=y&r=G)](https://gravatar.com/site/signup/)

Email (required) (Address never made public)

Name (required)

Website

![WordPress.com
Logo](http://s2.wp.com/wp-content/mu-plugins/highlander-comments/images/wplogo.png?m=1391188133g)

**** You are commenting using your WordPress.com account. ( [Log
Out](javascript:HighlanderComments.doExternalLogout(%20'wordpress'%20);)
/ [Change](#) )

![Twitter
picture](http://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&d=identicon&forcedefault=y&r=G)

**** You are commenting using your Twitter account. ( [Log
Out](javascript:HighlanderComments.doExternalLogout(%20'twitter'%20);) /
[Change](#) )

![Facebook
photo](http://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&d=identicon&forcedefault=y&r=G)

**** You are commenting using your Facebook account. ( [Log
Out](javascript:HighlanderComments.doExternalLogout(%20'facebook'%20);)
/ [Change](#) )

![Google+
photo](http://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&d=identicon&forcedefault=y&r=G)

**** You are commenting using your Google+ account. ( [Log
Out](javascript:HighlanderComments.doExternalLogout(%20'googleplus'%20);)
/ [Change](#) )

[Cancel](javascript:HighlanderComments.cancelExternalWindow();)

Connecting to %s

Notify me of follow-up comments via email.

Most Recent
===========

-   [Flowing Requirements from the VoC or
    VoP](http://tomhopper.me/2014/05/23/flowing-requirements-from-the-voc-or-vop/)
-   [Can We do Better than
    R-squared?](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/)
-   [Combining the Voice of the Customer with the Voice of the
    Process](http://tomhopper.me/2014/04/25/combining-the-voice-of-the-customer-with-the-voice-of-the-process/)
-   [Combining Expert
    Judgements](http://tomhopper.me/2014/04/18/combining-expert-judgements/)
-   [Issue Logs and Risk
    Registers](http://tomhopper.me/2014/04/11/issue-logs-and-risk-registers/)

Email Subscription
==================

Enter your email address to subscribe to this blog and receive
notifications of new posts by email.

Join 118 other followers

[Entertainment](http://tomhopper.me/category/entertainment/ "Entertainment (1)")
[New Product
Development](http://tomhopper.me/category/new-product-development/ "New Product Development (14)")
[Program and Project
Management](http://tomhopper.me/category/program-and-project-management/ "Program and Project Management (14)")
[Quality](http://tomhopper.me/category/quality-2/ "Quality (7)")
[RStats](http://tomhopper.me/category/rstats-2/ "RStats (8)")
[Science](http://tomhopper.me/category/science/ "Science (9)")
[Technology](http://tomhopper.me/category/technology/ "Technology (2)")
[Uncategorized](http://tomhopper.me/category/uncategorized/ "Uncategorized (5)")

Links
=====

[![View Thomas Hopper's profile on
LinkedIn](http://www.linkedin.com/img/webpromo/btn_myprofile_160x33.gif)](http://www.linkedin.com/in/tomhopper)

Top Posts
=========

-   [Can We do Better than
    R-squared?](http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/)
-   [Combining the Voice of the Customer with the Voice of the
    Process](http://tomhopper.me/2014/04/25/combining-the-voice-of-the-customer-with-the-voice-of-the-process/)
-   [Flowing Requirements from the VoC or
    VoP](http://tomhopper.me/2014/05/23/flowing-requirements-from-the-voc-or-vop/)
-   [A Simple Introduction to the Graphing Philosophy of
    ggplot2](http://tomhopper.me/2014/03/28/a-simple-introduction-to-the-graphing-philosophy-of-ggplot2/)
-   [Graphing Highly Skewed
    Data](http://tomhopper.me/2010/08/30/graphing-highly-skewed-data/)
-   [About](http://tomhopper.me/about/)
-   [Combining Expert
    Judgements](http://tomhopper.me/2014/04/18/combining-expert-judgements/)
-   [Hypotheses](http://tomhopper.me/hypotheses/)
-   [Issue Logs and Risk
    Registers](http://tomhopper.me/2014/04/11/issue-logs-and-risk-registers/)
-   [Normality and Testing for
    Normality](http://tomhopper.me/2014/03/21/normality-and-testing-for-normality/)

Archives
========

-   [May 2014](http://tomhopper.me/2014/05/)
-   [April 2014](http://tomhopper.me/2014/04/)
-   [March 2014](http://tomhopper.me/2014/03/)
-   [November 2011](http://tomhopper.me/2011/11/)
-   [September 2011](http://tomhopper.me/2011/09/)
-   [November 2010](http://tomhopper.me/2010/11/)
-   [September 2010](http://tomhopper.me/2010/09/)
-   [August 2010](http://tomhopper.me/2010/08/)
-   [May 2010](http://tomhopper.me/2010/05/)
-   [April 2009](http://tomhopper.me/2009/04/)
-   [March 2009](http://tomhopper.me/2009/03/)
-   [February 2009](http://tomhopper.me/2009/02/)
-   [September 2008](http://tomhopper.me/2008/09/)
-   [June 2008](http://tomhopper.me/2008/06/)
-   [January 2008](http://tomhopper.me/2008/01/)
-   [December 2007](http://tomhopper.me/2007/12/)
-   [November 2007](http://tomhopper.me/2007/11/)
-   [July 2007](http://tomhopper.me/2007/07/)
-   [June 2007](http://tomhopper.me/2007/06/)

[Blog at WordPress.com](http://wordpress.com/?ref=footer_blog). |
[Customized Sorbet
Theme](http://theme.wordpress.com/credits/tomhopper.me/ "Learn about customizing this theme with the Custom Design upgrade").

[Follow](javascript:void(0))

### Follow “Learning as You Go”

Get every new post delivered to your Inbox.

Join 118 other followers

[Powered by WordPress.com](http://wordpress.com/signup/?ref=lof)

Send to Email Address Your Name Your Email Address

![loading](http://s2.wp.com/wp-content/mu-plugins/post-flair/sharing/images/loading.gif?m=1315610318g)
[Cancel](#cancel)

Post was not sent - check your email addresses!

Email check failed, please try again

Sorry, your blog cannot share posts by email.

%d bloggers like this:

![image](http://stats.wordpress.com/b.gif?v=noscript)

This markdown document has been converted from the html document located at:
http://tomhopper.me/2014/05/16/can-we-do-better-than-r-squared/
