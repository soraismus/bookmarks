[Win-Vector Blog](http://www.win-vector.com/blog/)
==================================================

The Applied Theorist's Point of View

-   [Home](http://www.win-vector.com/blog/ "Home")
-   [About](http://www.win-vector.com/blog/about/)
-   [Popular Articles](http://www.win-vector.com/blog/popular-articles/)
-   [Practical Data Science with
    R](http://www.win-vector.com/blog/practical-data-science-with-r/)
-   [Pragmatic Machine
    Learning](http://www.win-vector.com/blog/pragmatic-machine-learning/)
-   [](javascript:void(0);)

[Home](http://www.win-vector.com/blog/ "Go to homepage") \>
[Applications](http://www.win-vector.com/blog/category/applications/ "View all posts in Applications"),
[Expository
Writing](http://www.win-vector.com/blog/category/expository-writing/ "View all posts in Expository Writing"),
[Pragmatic Data
Science](http://www.win-vector.com/blog/category/pragmatic-data-science/ "View all posts in Pragmatic Data Science"),
[Pragmatic Machine
Learning](http://www.win-vector.com/blog/category/pragmatic-machine-learning/ "View all posts in Pragmatic Machine Learning"),
[Statistics](http://www.win-vector.com/blog/category/statistics/ "View all posts in Statistics"),
[Statistics To English
Translation](http://www.win-vector.com/blog/category/statistics-to-english-translation/ "View all posts in Statistics To English Translation")
\> “I don’t think that means what you think it means;” Statistics to
English Translation, Part 1: Accuracy Measures

“I don’t think that means what you think it means;” Statistics to English Translation, Part 1: Accuracy Measures
----------------------------------------------------------------------------------------------------------------

November 3rd, 2009 [Nina
Zumel](http://www.win-vector.com/blog/author/nina-zumel/ "Posts by Nina Zumel")

Scientists, engineers, and statisticians share similar concerns about
evaluating the accuracy of their results, but they don’t always talk
about it in the same language. This can lead to misunderstandings when
reading across disciplines, and the problem is exacerbated when
technical work is communicated to and by the popular media.

The “Statistics to English Translation” series is a new set of articles
that we will be posting from time to time, as an attempt to bridge the
language gaps. Our goal is to increase statistical literacy: we hope
that you will find it easier to read and understand the statistical
results in research papers, even if you can’t replicate the analyses. We
also hope that you will be able to read popular media accounts of
statistical and scientific results more critically, and to recognize
common misunderstandings when they occur.

The first installment discusses some different accuracy measures that
are commonly used in various research communities, and how they are
related to each other. There is also a more legible PDF version of the
article
[here](http://win-vector.com/dfiles/StatisticsToEnglishPart1_Accuracy.pdf).

The Basics
----------

In informal language and in popular press articles, “accuracy” is often
discussed as if it were a one-dimensional property of a diagnostic test
or a classifier.

![Image
MyMoney](http://www.win-vector.com/blog/wp-content/uploads/2009/11/MyMoney.png)

In general though, a single number is not enough. A test or classifier
should detect what’s interesting, and ignore what’s not. How well it
accomplishes these two tasks is related to the two kinds of mistakes
that a test or classifier can make: false negatives, and false
positives.

For a classification task, *positive* means that an instance is labeled
as belonging to the class of interest: we may want to automatically
gather all news articles about Microsoft out of a news feed, or identify
fraudulent credit card transactions. For a screening test, positive
means that the test detects whatever it was designed to look for: an HIV
test detects the presence of human immunodeficiency virus, for example,
while an allergy test detects the presence of an allergic reaction. A
*negative* is obviously the opposite of a positive.

A *false positive* is concluding that something is positive when it is
not. False positives are sometimes called *Type I errors*. A *false
negative* is concluding that something is negative when it is not. False
negatives are sometimes called *Type II errors*. The terms “Type I
error” and “Type II error” are not terribly mnemonic, but they are
commonly used, and therefore worth knowing.

For binary classification or binary test procedures, the *False Positive
Rate*, ![$
FPR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img1.png)
, is the fraction of negative instances that are erroneously
misclassified as positive.

  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- -----
  ![$\\displaystyle FPR = \\frac{\\mbox{\\char93 false positives}} {\\mbox{all negative i... ...se positives}} {\\mbox{\\char93 false positives} + \\mbox{\\char93 true negatives}}$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img2.png)   (1)
  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- -----

\

Likewise, the *False Negative Rate*, ![$
FNR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img3.png)
, is the fraction of positive instances that are erroneously
misclassified as negative.

  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- -----
  ![$\\displaystyle FNR = \\frac {\\mbox{\\char93 false negatives}} {\\mbox{all positive ... ...se negatives}} {\\mbox{\\char93 false negatives} + \\mbox{\\char93 true positives}}$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img4.png)   (2)
  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- -----

\

The *True Positive Rate*, ![$
TPR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img5.png)
, is the fraction of positive instances that are correctly identified as
such. It follows from the Definition [2](#eqn:fn) above that \
 ![$ TPR = 1 -
FNR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img6.png)
.

The *True Negative Rate*, ![$
TNR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img7.png)
, is the fraction of negative instances that are correctly identified as
such. It follows from the Definition [1](#eqn:fp) above that \
 ![$ TNR = 1 -
FPR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img8.png)
.

Sensitivity and Specificity
---------------------------

![Image
screening](http://www.win-vector.com/blog/wp-content/uploads/2009/11/screening.jpg)

The terms sensitivity and specificity generally refer to diagnostic or
screening procedures, such as an HIV or allergy tests. The *sensitivity*
of a test is its true positive rate; the *specificity* is its true
negative rate, although it can be more intuitive to think of specificity
as the complement of the false positive rate: *Specificity* = \
 ![$ TNR = (1 -
FPR)$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img9.png)
.

The Wikipedia entry on Sensitivity and Specificity [[Wik](#wikiSS)] uses
a nice example to illustrate the difference: think of a drug-sniffing
dog as a screening test for illicit drugs. If the dog’s nose is highly
*sensitive* to the smell of drugs, then it will detect all the hidden
packets of drugs; if it is less sensitive, then it will fail to detect
some of the packets. At the same time, the dog should react
*specifically* to drugs, and not, say, jambalaya or doggie biscuits. If
the dog is highly specific in its reactions, it will only react to
drugs; if it is less specific, then it will react to the occasional care
package of yummy home cooking from Mom.

Screening tests may trade off specificity for sensitivity (and
vice-versa). To go back to our drug-sniffing example, we might treat
every suitcase and bag that comes through the airport as if it contained
drugs; this procedure is perfectly sensitive (it will detect every
packet of drugs, for sure), but not specific at all. Or, we might assume
that no one is carrying drugs. This is perfectly specific (we will never
make a false accusation), but not sensitive at all.

A more realistic example, inspired by a discussion of mandatory AIDS
testing by Joshua Rosenau [[Ros06](#Rosenau)], is the use of the ELISA
screening test to detect HIV-infected blood donations. The ELISA test is
designed to be very sensitive: it detects 99.7% of the cases of
HIV-infection, which gives a false negative rate of \
 ![$ 3 \\times
10\^{-3}$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img10.png)
. On the other hand, it is not very specific: it has a 1.9% false
positive rate[^1^](#foot208). If you assume that the incidence of
HIV-positive individuals in the general population is about 448 out of
every 100,000 people [[Hig08](#CDC)], then a positive test result is
correct only about 19% of the time: one case of true infection out of
every five positives. This error rate may be appropriate for screening
blood donations, since it is better to discard four perfectly good pints
of blood, “just in case”, than to allow a pint of HIV-infected blood
into the blood bank. But it is *not* appropriate to assume that all five
of those poor blood donors are HIV-positive, without followup tests to
increase the specificity of the screening procedure.

### Sensitivity, Specificity, and Prevalence

The example above brings up an important point. Sensitivity and
specificity are properties *of the test itself*, not *how the test
performs in a given population*. **The absolute accuracy** (as the term
is commonly understood) **of a screening test will change, depending on
the prevalence of the condition that the test is screening for.**

Let’s imagine the ELISA test described above as an HIV-screening daemon,
who uses two coins to generate uncertainty. When the daemon is shown a
pint of infected blood, she flips an unfair quarter. If the quarter
comes up heads (which it does 3 times out of every 1000 flips), then she
lies and says the blood is uninfected, otherwise she tells the truth.
When the daemon is shown a pint of uninfected blood, she flips a silver
dollar that comes up heads about 2 times out of every 100 flips. If the
silver dollar comes up heads, she lies and says the blood is infected,
or else she tells the truth. The quarter and the silver dollar encode
ELISA’s sensitivity and specificity, respectively.

**Figure 1:** The ELISA daemon screening an uninfected pint of blood

![Image
ELISAflip](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ELISAflip.png)

Suppose ELISA looks at the blood of 1000 people a day, drawn from the
general population. We can expect that about 5 of them are truly
infected. That means that ELISA flips her silver dollar 995 times; it
will come up heads about 20 times. That’s about twenty false positives a
day. She’ll flip the quarter about 5 times, and with high probability,
won’t ever see a head. That’s near zero false negatives a day. In total,
ELISA will read positive for about 25 pints of blood every day, and she
will be wrong for 80% of those cases.

But suppose ELISA looks at the blood of 1000 people from a high-risk
population, where one out of four people are infected. Then ELISA flips
her silver dollar about 750 times, and it will come up heads about 15
times: 15 false positives. She’ll also flip the quarter 250 times; the
coin just might come up heads one time. Let’s say it does. Then ELISA
will read positive for 249+15 = 264 pints of blood, and she’ll be wrong
for only about 6% of those cases – plus that case of infection that she
missed.

**Same test, same sensitivity and specificity, but different overall
accuracy.** The percentage of positives that are actually true positives
in a given population is called the *positive predictive value* (![$
PPV$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img11.png)
) of the test within that population; it is the probability *for that
population* that a positive test result correctly predicts a positive
instance.

  ------------------------------------------------------------------------------------------------------------------------------------------------------------------ -----
  ![$\\displaystyle PPV = \\frac{TPR \\times P(+)}{TPR \\times P(+) + FPR \\times P(-)}$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img12.png)   (3)
  ------------------------------------------------------------------------------------------------------------------------------------------------------------------ -----

\
\
 where ![$
P(+)$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img13.png)
is the probability of a positive instance, or in other words the
prevalence of the condition in the population. ![$
P(-)$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img14.png)
is the probability of a negative instance, and of course \
 ![$ P(+) + P(-) =
1$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img15.png)
.[^2^](#foot86)

### Likelihood Ratios

Likelihood ratios are another measure of diagnostic test accuracy. The
*positive likelihood ratio* is the true positive rate over the false
positive rate: \
 ![$ LR\_P =
TPR/FPR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img16.png)
. For our example ELISA test, the positive likelihood ratio is
0.997/0.019 = 52.47. The *negative likelihood ratio* is the false
negative rate over the true negative rate, \
 ![$ LR\_N
=FNR/TNR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img17.png)
. For our ELISA example, the negative likelihood ratio is 0.003/.981 =
0.003058.

Likelihood ratios are a property of the screening test, independent of
the prevalence of the condition in the population. If you know the odds
of infection for the population of interest, \
 ![$ odds\_{pop} =
P(+)/P(-)$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img18.png)
, then you can calculate the posterior odds of infection for someone who
has tested positive:

![$\\displaystyle odds\_{post} = LR\_P \\times odds\_{pop}
$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img19.png)

and the posterior odds of infection for someone who has tested negative:

![$\\displaystyle odds\_{post} = LR\_N \\times odds\_{pop}
$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img20.png)

It’s been argued that likelihood ratios make it easier for
non-statistically-minded practitioners to interpret the results of a
test than sensitivity and specificity do [[JGS94](#JAMA94)]. It’s also
been argued the other way [[PSBtR05](#AIM05)]. Which framework makes
more sense depends on if you prefer thinking in odds or probabilities.
In either case you should be leery of “guidelines” of the sort: “![$
LR\_P \>
10$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img21.png)
indicates large and often conclusive increase in the likelihood of the
disease.” There is certainly a large increase in the posterior
likelihood of infection if ![$ LR\_P \>
10$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img21.png)
, but as the ELISA coin-flipping example should have made clear, this
posterior likelihood can still be quite small, if the disease is
sufficiently rare.

I occasionally see something called the *diagnostic odds ratio*. It was
developed as “a single indicator of test performance,” and I’ve seen it
described as “the odds of the true positive rate divided by the odds of
the false positive rate” [[HC07](#diagodds)]. I could give you the
actual formula here, but frankly – it makes no sense. The whole point of
having two measures for accuracy is that one is not enough, and if you
absolutely must have one number, you are better off using something like
the ![$
F\_1$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img22.png)
measure that we describe in the next section.

Precision and Recall
--------------------

![Image
istock\_library](http://www.win-vector.com/blog/wp-content/uploads/2009/11/istock_library.jpg)

Precision and recall are similar (but not identical) to sensitivity and
specificity. The measures are popular in the information retrieval and
machine learning communities.

*Recall* is the same as sensitivity, or the true positive rate: the
number of true examples correctly classified as such. *Precision* is
defined as the fraction of instances classified as positive that really
are positive:

precision![$\\displaystyle = \\frac{\\mbox{\\char93 true
positives}}{\\mbox{\\char93 true positives + \\char93 false positives}}
$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img23.png)

This is *not* the same as specificity; it is the same as the positive
predictive value, and is a joint property of the classifier and the
population that it was evaluated on.

Information retrieval research concerns itself with efficient discovery
of relevant documents from document collections, and that domain
motivates the definitions of precision and recall. A library patron
queries the library catalog for books on a given topic; the catalog’s
search engine should return all of the books relevant to her query, and
only those books. Recall is a measure of how well the search delivers
“all of the relevant books”, and precision is a measure of how well it
delivers “only the relevant books”. If recall is poor, then the patron
will miss finding many relevant books; if precision is poor, then she
will be inundated with a bunch of book suggestions that have nothing to
do with her search.

As with diagnostic procedures, classifiers may trade precision for
recall, and vice-versa. Suppose our library patron is looking for novels
about vampires. She could request all novels with the word “vampire” in
the title. This search would have almost perfect precision, since
presumably a novel with the word “vampire” in the title is going to be
about vampires. It would not have perfect recall, since many novels
about vampires – like *Dracula*, or the books from the *Twilight* series
– don’t announce themselves quite that blatantly. Now suppose she is
only interested in novels from Anne Rice’s *Vampire Chronicles* series.
She could request all novels authored by Anne Rice. This search would
have perfect recall, but not perfect precision, since Ms. Rice did in
fact write several novels that are not about vampires.

These examples show that neither high precision nor high recall
guarantee a useful classifier. It is the tension between achieving high
precision and high recall that leads to good classifiers.

As we discussed above, the primary difference between precision and
specificity is that precision is a property of *the algorithm and the
population*. One could argue that precision is a more appropriate
measure than specificity for many classification and machine learning
tasks, especially those related to text or natural language. The
fundamental assumption, after all, is that such algorithms are trained
on data that is representative of the population that the classifier
will be deployed in.

### If you insist: Single Score Measures

There is another measure called ![$
F\_1$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img22.png)
, the harmonic mean of precision and recall:

![$\\displaystyle F\_1 = \\frac{2}{(1/\\mbox{precision} +
1/\\mbox{recall})} = 2 \\times \\frac{\\mbox{precision} \\times
\\mbox{recall}}{\\mbox{precision + recall}}.
$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img24.png)

![$
F\_1$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img22.png)
is near one when both precision and recall are high, and near zero when
they are both low. It is a convenient single score to characterize
overall accuracy, especially for comparing the performance of different
classifiers.

Using ![$
F\_1$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img22.png)
to compare classifiers assumes that precision and recall are equally
important for the application. If one criterion is more important than
the other, then one can also use the weighted geometric mean:

![$\\displaystyle F\_\\alpha = (1 +
\\alpha)($](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img25.png)precision![$\\displaystyle
\\times$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img26.png)
recall![$\\displaystyle
)/(\\alpha$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img27.png)
precision + recall![$\\displaystyle ).
$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img28.png)

![$
\\alpha$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img29.png)
describes how much more important recall is than precision: use ![$
F\_2$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img30.png)
if recall is twice as important as precision, ![$
F\_{0.5}$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img31.png)
if precision is twice as important as recall.

It is still better to have separate target goals for precision and
recall that a candidate classifier must meet. Still, ![$
F\_1$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img22.png)
and ![$
F\_\\alpha$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img32.png)
are found in the literature, so they are presented here.

ROC Curves
----------

Not all diagnostic tests or classifiers return a simple “yes-or-no”
answer. In fact, most probably don’t. Generally, a classification or
diagnostic procedure will return a score along a continuum; ideally, the
positive instances score towards one end of the scale, and the negative
examples towards the other end. It is up to the scientist or the analyst
to set a threshold on that score that separates what is considered a
positive result from what is considered a negative result. The Receiver
Operating Characteristic Curve, or *ROC Curve*, is a tool that helps set
the best threshold.

**Figure 2:** Plot of score distributions for positive and negative
instances (Class 10 is positive)

![Image
ScoreDensityplots](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ScoreDensityplots.png)

Suppose we are trying to classify a set of instances into one of two
classes, positive and negative[^3^](#foot133). We’ve gathered a test set
of representative samples, and we’ve developed a scoring procedure to
try to separate them. Positives tend to score on the high end of the
scale, negatives toward the low end. We want to pick a threshold value.

Figure [2](#fig:densityplots) shows what happens when score the test
set. We can see that the scores of the positive instances (class 10) are
in a cluster centered just above 7, and the scores of the negatives
(class 0) are in a cluster centered near 5. Still, there is an interval
where the two clusters overlap substantially. If we pick a threshold to
the right of that interval (say, ![$ T =
7$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img33.png)
), almost everything that scores greater than ![$
T$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img34.png)
will be truly positive (high precision/specificity), but we miss a lot
of positives, too (low recall/sensitivity). If we pick a threshold to
the left of that interval (say ![$ T =
5$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img35.png)
), we will catch almost all the positives (high recall/sensitivity), but
we will also pick up a lot of negatives (low specificity/precision). So
we want the threshold to be somewhere in the overlap interval, but
where?

**Figure 3:** ROC Curve corresponding to Figure [2](#fig:densityplots).
Selected thresholds are marked on the curve.

![Image
ROC](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ROC.png)

ROC curves plot the false positive rate on the x-axis and the true
positive rate on the y-axis, as we vary the threshold. The point ![$
(0,0)$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img36.png)
corresponds to rejecting everything; the point ![$
(1,1)$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img37.png)
corresponds to accepting everything. The ideal point is ![$
(0,1)$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img38.png)
: accept all positive instances and reject all negative instances. The
line ![$
x=y$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img39.png)
corresponds to random guessing: that is, a procedure that assigns each
instance a score uniformly drawn from (in this example) the interval ![$
[1,8]$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img40.png)
without even checking if the instance is positive or negative.

The ROC curve represents the tradeoff between true positives and false
positives that we make as we increase the threshold from accepting
everything to rejecting everything. Figure [3](#fig:ROC) gives the ROC
curve for our example, with a few example thresholds marked on the
curve.

The area between the ROC curve and the ![$
x=y$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img39.png)
line can be considered a measure of accuracy; the smaller that area, the
more the scoring procedure is like random guessing. The larger the area,
the better separated the two classes are. We can use the curve to help
us decide how to set a threshold that will give us the most acceptable
tradeoff between true positives and false positives. For this example,
we would probably want to select a threshold somewhere between ![$
6$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img41.png)
and ![$
6.5$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img42.png)
.

In Conclusion
-------------

Some points to remember:

-   Classifier and diagnostic test performance are not one-dimensional.
-   Different fields use different (but related) measures of accuracy.
-   Classifier and diagnostic test performance depend on the relative
    cost of Type I and Type II errors, as well as on the proportion of
    positive and negative instances in the population of interest.

Bibliography
------------

HC07
  ~ Childrens Mercy Hospitals and Clinics, *Stats: Meta-analysis for a
    diagnostic test*,
    `http://www.childrens-mercy.org/stats/model/diagnostic.asp`, 2007.
Hig08
  ~ Liz Highleyman, *CDC updates estimates of HIV prevalence in the
    United States*,
    `http://www.hivandhepatitis.com/recent/2008/100708_a.html`, 2008.
JGS94
  ~ R. Jaeschke, GH Guyatt, and DL Sackett, *Users’ guides to the
    medical literature. III. How to use an article about a diagnostic
    test. B. What are the results and will they help me in caring for my
    patients? The evidence-based medicine working group*, JAMA **271**
    (1994), no. 6, 703-707.
Org04
  ~ World Health Organization, *HIV assays: Operational characteristics
    (phase 1); Report 15 antigen/antibody ELISAs*,
    `http://whqlibdoc.who.int/publications/2004/9241592370.pdf`, 2004.
PSBtR05
  ~ MA Puhan, J. Steurer, LM Bachmann, and G. ter Riet, *“A randomized
    trial of ways to describe test accuracy: the effect on physicians’
    post-test probability estimates”*, Annals of Internal Medicine
    **143** (2005), no. 3, 184-âÄì189.
Ros06
  ~ Joshua Rosenau, *AIDS testing*,
    `http://scienceblogs.com/tfk/2006/08/aids_testing.php`, 2006.
Wik
  ~ Wikipedia, *Sensitivity and specificity*,
    `http://en.wikipedia.org/wiki/Sensitivity_and_specificity)`.

Appendix: Glossary of Accuracy Terms
------------------------------------

### Basic Terms

**Accuracy**
  ~ 

    ![$\\displaystyle \\frac{\\mbox{\\char93 true positives} +
    \\mbox{\\char93 true negatives}}{\\mbox{all instances}}
    $](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img43.png)

**Type I error**
  ~ False Positive: to conclude something is a positive instance when it
    is not.
**Type II error**
  ~ False Negative: to conclude something is a negative instance when it
    is not.
**False Positive Rate (![$
FPR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img1.png)
)**
  ~ The fraction of negative instances that are erroneously
    misclassified as positive.
      ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- --
      ![$\\displaystyle FPR = \\frac{\\mbox{\\char93 false positives}} {\\mbox{all negative i... ...se positives}} {\\mbox{\\char93 false positives} + \\mbox{\\char93 true negatives}}$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img2.png)   
      ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- --

    \
**False Negative Rate (![$
FNR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img3.png)
)**
  ~ The fraction of positive instances that are erroneously
    misclassified as negative.
      ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- --
      ![$\\displaystyle FNR = \\frac {\\mbox{\\char93 false negatives}} {\\mbox{all positive ... ...se negatives}} {\\mbox{\\char93 false negatives} + \\mbox{\\char93 true positives}}$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img4.png)   
      ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- --

    \
**True Positive Rate (![$
TPR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img5.png)
)**
  ~ The fraction of positive instances that are correctly identified as
    such. \
     ![$ TPR = 1 -
    FNR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img6.png)
    .
**True Negative Rate (![$
TNR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img7.png)
)**
  ~ The fraction of negative instances that are correctly identified as
    such. \
     ![$ TNR = 1 -
    FPR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img8.png)
    .
**Prevalence ![$
P(+)$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img13.png)**
  ~ The proportion of positive instances in the population, or the
    probability that someone drawn from the population at random in a
    positive instance. ![$
    P(-)$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img14.png)
    is the probability of drawing a negative instance from the
    population at random. The *odds of a positive* is the ratio of ![$
    P(+)$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img13.png)
    to ![$
    P(-)$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img14.png)
    .

    ![$\\displaystyle odds\_{pop} = P(+)/P(-)
    $](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img44.png)

### Accuracy Terms

Terms to describe the accuracy of diagnostic tests are conventionally
given in terms of sensitivity and specificity. They have been rephrased
here in terms of true positive rate, false positive rate, etc., for
clarity.

**![$
F\_1$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img22.png)**
  ~ Single score measure of accuracy. The harmonic mean of precision and
    recall.

    ![$\\displaystyle F\_1 = \\frac{2}{(1/\\mbox{precision} +
    1/\\mbox{recall})} = 2 \\times \\frac{\\mbox{precision} \\times
    \\mbox{recall}}{\\mbox{precision + recall}}.
    $](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img24.png)

    ![$
    F\_1$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img22.png)
    is near 1 for high accuracy, near 0 for low accuracy. Also see
    *Precision, Recall*.

**![$
F\_2$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img30.png)**
  ~ Single score measure of accuracy when recall is twice as important
    as precision. Also see *![$
    F\_1$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img22.png)
    , Precision, Recall*.
**![$
F\_0.5$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img45.png)**
  ~ Single score measure of accuracy when precision is twice as
    important as recall. Also see *![$
    F\_1$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img22.png)
    , Precision, Recall*.
**Likelihood-ratio (negative)**
  ~ \
     ![$ LR\_N
    =FNR/TNR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img17.png)
    . In diagnostic screening, used for calculating the posterior odds
    of a true positive for a subject who has tested positive:

    ![$\\displaystyle odds\_{post} = LR\_N \\times odds\_{pop}
    $](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img20.png)

**Likelihood-ratio (positive)**
  ~ \
     ![$ LR\_P =
    TPR/FPR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img16.png)
    . In diagnostic screening, used for calculating the posterior odds
    of a positive for a subject who has tested negative:

    ![$\\displaystyle odds\_{post} = LR\_P \\times odds\_{pop}
    $](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img19.png)

**Positive Predictive Value**
  ~ Probability (with respect to a specific assumed prevalence rate)
    that a positive result from a diagnostic or screening procedure is a
    true positive. Same as precision.

    ![$\\displaystyle PPV = \\frac{TPR \\times P(+)}{TPR \\times P(+) +
    FPR \\times
    P(-)}$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img12.png)

    Also see *Precision*

**Precision**
  ~ In information retrieval, the fraction of returned documents that
    are actually relevant to the query. In classification, the fraction
    of all instances classified as class A that are truly in class A.
    The same as Positive Predictive Value.

    precision![$\\displaystyle = \\frac{\\mbox{\\char93 true
    positives}}{\\mbox{\\char93 true positives + \\char93 false
    positives}}
    $](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img23.png)

    Also see *Positive Predictive Value*

**Recall**
  ~ In information retrieval, the fraction of relevant documents that
    are returned by the query. In classification, the fraction of all
    true instances of class A that are classified into class A. The same
    as sensitivity.

    recall![$\\displaystyle = \\frac{\\mbox{\\char93 true
    positives}}{\\mbox{\\char93 true positives + \\char93 false
    negatives}} = TPR
    $](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img46.png)

    Also see *Sensitivity*

**ROC Curve**
  ~ Plot of true positive rate versus false positive rate for a
    diagnostic test or binary classifier, as the decision threshold is
    varied.
**Sensitivity**
  ~ The true positive rate ![$
    TPR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img5.png)
    of a diagnostic or screening procedure. Also see *Recall*.
**Specificity**
  ~ The true negative rate \
     ![$ TNR = 1 -
    FPR$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img8.png)
    (or the complement of the false positive rate) of a diagnostic or
    screening procedure.

* * * * *

#### Footnotes

… rate[^1^](#tex2html2)
  ~ The ELISA sensitivity and specificity numbers are from WHO’s report
    on the operational characteristics of HIV Assays [[Org04](#who), p.
    18], using the lower bounds of the confidence interval. They are
    slightly different from the numbers Rosenau uses
….[^2^](#tex2html4)
  ~ The definition of ![$
    PPV$](http://www.win-vector.com/blog/wp-content/uploads/2009/11/ste1img11.png)
    is conventionally given in terms of sensitivity and specificity
    (similarly for the likelihood ratios discussed in the following
    section). The definitions in this article are given in terms of
    false positive rate, etc., since that is clearer for people reading
    outside their discipline.
… negative[^3^](#tex2html6)
  ~ We are using a classifier in our example, but a diagnostic test
    would work the same way.

* * * * *

* * * * *

Be Sociable, Share!

-   [](http://twitter.com/intent/tweet?text=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures%20-%20http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F%20%20%20 "Twitter")
-   [](http://www.facebook.com/share.php?u=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&t=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures "Facebook")
-   [](https://mail.google.com/mail/?view=cm&fs=1&to&su=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures&body=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&ui=2&tf=1&shva=1 "email")
-   -   [](http://www.stumbleupon.com/submit?url=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&title=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures "StumbleUpon")
-   [](http://delicious.com/post?url=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&title=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures&notes=Scientists%2C%20engineers%2C%20and%20statisticians%20share%20similar%20concerns%20about%20evaluating%20the%20accuracy%20of%20their%20results%2C%20but%20they%20don%27t%20always%20talk%20about%20it%20in%20the%20same%20language.%20This%20can%20lead%20to%20misunderstandings%20when%20reading%20across%20disciplines%2C%20and%20the%20prob "Delicious")
-   [](http://www.google.com/reader/link?url=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&title=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures&srcURL=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&srcTitle=Win-Vector+Blog+The+Applied+Theorist%26%23039%3Bs+Point+of+View "Google Reader")
-   [](http://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&title=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures&source=Win-Vector+Blog+The+Applied+Theorist%26%23039%3Bs+Point+of+View&summary=Scientists%2C%20engineers%2C%20and%20statisticians%20share%20similar%20concerns%20about%20evaluating%20the%20accuracy%20of%20their%20results%2C%20but%20they%20don%27t%20always%20talk%20about%20it%20in%20the%20same%20language.%20This%20can%20lead%20to%20misunderstandings%20when%20reading%20across%20disciplines%2C%20and%20the%20prob "LinkedIn")
-   [](http://www.blinklist.com/index.php?Action=Blink/addblink.php&Url=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&Title=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures "BlinkList")
-   ![image](http://www.win-vector.com/blog/wp-content/plugins/sociable/images/more.png)

-   [](http://www.myspace.com/Modules/PostTo/Pages/?u=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&t=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures "Myspace")
-   [](http://digg.com/submit?phase=2&url=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&title=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures&bodytext=Scientists%2C%20engineers%2C%20and%20statisticians%20share%20similar%20concerns%20about%20evaluating%20the%20accuracy%20of%20their%20results%2C%20but%20they%20don%27t%20always%20talk%20about%20it%20in%20the%20same%20language.%20This%20can%20lead%20to%20misunderstandings%20when%20reading%20across%20disciplines%2C%20and%20the%20prob "Digg")
-   [](http://reddit.com/submit?url=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&title=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures "Reddit")
-   [](http://www.google.com/bookmarks/mark?op=edit&bkmk=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&title=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures&annotation=Scientists%2C%20engineers%2C%20and%20statisticians%20share%20similar%20concerns%20about%20evaluating%20the%20accuracy%20of%20their%20results%2C%20but%20they%20don%27t%20always%20talk%20about%20it%20in%20the%20same%20language.%20This%20can%20lead%20to%20misunderstandings%20when%20reading%20across%20disciplines%2C%20and%20the%20prob "Google Bookmarks")
-   [](http://news.ycombinator.com/submitlink?u=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&t=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures "HackerNews")
-   [](http://reporter.es.msn.com/?fn=contribute&Title=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures&URL=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&cat_id=6&tag_id=31&Remark=Scientists%2C%20engineers%2C%20and%20statisticians%20share%20similar%20concerns%20about%20evaluating%20the%20accuracy%20of%20their%20results%2C%20but%20they%20don%27t%20always%20talk%20about%20it%20in%20the%20same%20language.%20This%20can%20lead%20to%20misunderstandings%20when%20reading%20across%20disciplines%2C%20and%20the%20prob "MSNReporter")
-   [](http://sphinn.com/index.php?c=post&m=submit&link=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F "Sphinn")
-   [](http://posterous.com/share?linkto=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&title=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures&selection=Scientists%2C%20engineers%2C%20and%20statisticians%20share%20similar%20concerns%20about%20evaluating%20the%20accuracy%20of%20their%20results%2C%20but%20they%20don%27t%20always%20talk%20about%20it%20in%20the%20same%20language.%20This%20can%20lead%20to%20misunderstandings%20when%20reading%20across%20disciplines%2C%20and%20the%20prob "Posterous")
-   [](http://www.tumblr.com/share?v=3&u=http%3A%2F%2Fwww.win-vector.com%2Fblog%2F2009%2F11%2Fi-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures%2F&t=%22I%20don%27t%20think%20that%20means%20what%20you%20think%20it%20means%3B%27%27%20Statistics%20to%20English%20Translation%2C%20Part%201%3A%20Accuracy%20Measures&s=Scientists%2C%20engineers%2C%20and%20statisticians%20share%20similar%20concerns%20about%20evaluating%20the%20accuracy%20of%20their%20results%2C%20but%20they%20don%27t%20always%20talk%20about%20it%20in%20the%20same%20language.%20This%20can%20lead%20to%20misunderstandings%20when%20reading%20across%20disciplines%2C%20and%20the%20prob "Tumblr")

![image](http://www.win-vector.com/blog/wp-content/plugins/sociable/images/closelabel.png "close")

-   [Tweet](https://twitter.com/share)
-   -   -   -   

Related posts:

1.  [Statistics to English Translation, Part 2a: ’Significant’ Doesn’t
    Always Mean
    ’Important’](http://www.win-vector.com/blog/2009/12/statistics-to-english-translation-part-2a-significant-doesnt-always-mean-important/ "Statistics to English Translation, Part 2a: ’Significant’ Doesn’t Always Mean ’Important’")
2.  [Statistics to English Translation, Part 2b: Calculating
    Significance](http://www.win-vector.com/blog/2009/12/statistics-to-english-translation-part-2b-calculating-significance/ "Statistics to English Translation, Part 2b: Calculating Significance")
3.  [More on
    ROC/AUC](http://www.win-vector.com/blog/2013/01/more-on-rocauc/ "More on ROC/AUC")
4.  [Data Science, Machine Learning, and Statistics: what is in a
    name?](http://www.win-vector.com/blog/2013/04/data-science-machine-learning-and-statistics-what-is-in-a-name/ "Data Science, Machine Learning, and Statistics: what is in a name?")
5.  [Bayesian and Frequentist Approaches: Ask the Right
    Question](http://www.win-vector.com/blog/2013/05/bayesian-and-frequentist-approaches-ask-the-right-question/ "Bayesian and Frequentist Approaches: Ask the Right Question")

![YARPP](http://yarpp.org/pixels/b8781af2b90c83bd11d1e98c04b31afb)

Categories:
[Applications](http://www.win-vector.com/blog/category/applications/ "View all posts in Applications"),
[Expository
Writing](http://www.win-vector.com/blog/category/expository-writing/ "View all posts in Expository Writing"),
[Pragmatic Data
Science](http://www.win-vector.com/blog/category/pragmatic-data-science/ "View all posts in Pragmatic Data Science"),
[Pragmatic Machine
Learning](http://www.win-vector.com/blog/category/pragmatic-machine-learning/ "View all posts in Pragmatic Machine Learning"),
[Statistics](http://www.win-vector.com/blog/category/statistics/ "View all posts in Statistics"),
[Statistics To English
Translation](http://www.win-vector.com/blog/category/statistics-to-english-translation/ "View all posts in Statistics To English Translation")
Tags: [Accuracy
Measures](http://www.win-vector.com/blog/tag/accuracy-measures/),
[Classifiers](http://www.win-vector.com/blog/tag/classifiers/),
[Diagnostic
Tests](http://www.win-vector.com/blog/tag/diagnostic-tests/), [Precision
and Recall](http://www.win-vector.com/blog/tag/precision-and-recall/),
[ROC Curves](http://www.win-vector.com/blog/tag/roc-curves/),
[Sensitivity and
Specificity](http://www.win-vector.com/blog/tag/sensitivity-and-specificity/),
[Statistics](http://www.win-vector.com/blog/tag/statistics/)

[Comments (4)](javascript:void(0);)

1.  [Brian Slesinsky](http://slesinsky.org/brian/)

    November 7th, 2009 at 10:08 | [\#1](#comment-1560)

    [Reply](javascript:void(0);) | [Quote](javascript:void(0);)

    Great stuff!

    I also found this article useful. It also explains how test results
    are two-dimensional, and I learned to correctly apply Bayes’ theorem
    by punching numbers into a calculator, without having to look up the
    formula:

    An Intuitive Explanation of Bayes’ Theorem\

    [http://yudkowsky.net/rational/bayes](http://yudkowsky.net/rational/bayes)

2.  [Nina Zumel](http://mzlabs.com/NBZumel/)

    November 23rd, 2009 at 13:33 | [\#2](#comment-1589)

    [Reply](javascript:void(0);) | [Quote](javascript:void(0);)

    Brian: Glad you liked it (and apologies for responding so late…)!

    The article you posted was also recommended to me by another friend;
    I haven’t had a chance to check it out yet, but two favorable
    comments are a point in its favor.

3.  [jmount](http://www.win-vector.com)

    December 12th, 2009 at 15:31 | [\#3](#comment-1650)

    [Reply](javascript:void(0);) | [Quote](javascript:void(0);)

    Part 2a now posted:
    [http://www.win-vector.com/blog/2009/12/statistics-to-english-translation-part-2a-’significant’-doesn’t-always-mean-’important’/](http://www.win-vector.com/blog/2009/12/statistics-to-english-translation-part-2a-’significant’-doesn’t-always-mean-’important’/)

4.  Beth Clemensen

    March 10th, 2010 at 09:30 | [\#4](#comment-1988)

    [Reply](javascript:void(0);) | [Quote](javascript:void(0);)

    Thank you, thank you. When I was in high school girls were not
    allowed to take more than two years of math. Of course, in college
    that left me out of the game entirely. I’m happy to have been a
    librarian, I’m retired now, but every once in a while I read
    something like this and really enjoy it. Thank you!

Comments are closed.

[The Local to Global
Principle](http://www.win-vector.com/blog/2009/11/the-local-to-global-principle/)
[Google AdSense Channels IDs and the Cramer Rao
Inequality](http://www.win-vector.com/blog/2009/10/google-adsense-channels-ids-and-the-cramer-rao-inequality/)

[RSS](http://www.win-vector.com/blog/feed/ "Subscribe to this blog...")

-   [Google](http://fusion.google.com/add?feedurl=http://www.win-vector.com/blog/feed/ "Subscribe with Google")
-   [Youdao](http://reader.youdao.com/#url=http://www.win-vector.com/blog/feed/ "Subscribe with Youdao")
-   [Xian
    Guo](http://www.xianguo.com/subscribe.php?url=http://www.win-vector.com/blog/feed/ "Subscribe with Xian Guo")
-   [Zhua
    Xia](http://www.zhuaxia.com/add_channel.php?url=http://www.win-vector.com/blog/feed/ "Subscribe with Zhua Xia")
-   [My
    Yahoo!](http://add.my.yahoo.com/rss?url=http://www.win-vector.com/blog/feed/ "Subscribe with My Yahoo!")
-   [newsgator](http://www.newsgator.com/ngs/subscriber/subfext.aspx?url=http://www.win-vector.com/blog/feed/ "Subscribe with newsgator")
-   [Bloglines](http://www.bloglines.com/sub/http://www.win-vector.com/blog/feed/ "Subscribe with Bloglines")
-   [iNezha](http://inezha.com/add?url=http://www.win-vector.com/blog/feed/ "Subscribe with iNezha")

[Twitter](http://twitter.com/WinVectorLLC/ "Follow me!")

### Subscribe

[subscribe](http://www.win-vector.com/blog/feed/)

### Credit

Win-Vector Blog (The Applied Theorist's Point of View) is part of
[Win-Vector LLC](http://www.win-vector.com/), authors [John
Mount](http://www.win-vector.com/Staff/JohnMount/JohnMount.html) and
[Nina Zumel](http://www.win-vector.com/Staff/NinaZumel/NinaZumel.html).

All material Copyright [Win-Vector LLC](http://www.win-vector.com/).
Some material under redistribution agreement.

### Pages

-   [About](http://www.win-vector.com/blog/about/)
-   [Popular Articles](http://www.win-vector.com/blog/popular-articles/)
-   [Practical Data Science with
    R](http://www.win-vector.com/blog/practical-data-science-with-r/)
-   [Pragmatic Machine
    Learning](http://www.win-vector.com/blog/pragmatic-machine-learning/)

### Practical Data Science with R

[![image](http://www.manning.com/zumel/zumel_cover150.jpg)](http://affiliate.manning.com/idevaffiliate.php?id=1273_360)

### Recent Posts

-   [Can a classifier that never says “yes” be
    useful?](http://www.win-vector.com/blog/2014/03/can-a-classifier-that-never-says-yes-be-useful/)
-   [Some statistics about the
    book](http://www.win-vector.com/blog/2014/03/some-statistics-about-the-book/)
-   [The Statistics behind “Verification by
    Multiplicity”](http://www.win-vector.com/blog/2014/03/the-statistics-behind-verification-by-multiplicity/)
-   [Drowning in
    insignificance](http://www.win-vector.com/blog/2014/02/drowning-in-insignificance/)
-   [One day discount on Practical Data Science with
    R](http://www.win-vector.com/blog/2014/02/one-day-discount-on-practical-data-science-with-r/)

### Tags

[AdSense](http://www.win-vector.com/blog/tag/adsense/ "2 topics")
[AdSense
Channel](http://www.win-vector.com/blog/tag/adsense-channel/ "2 topics")
[Analytics](http://www.win-vector.com/blog/tag/analytics/ "4 topics")
[Cloud
Computing](http://www.win-vector.com/blog/tag/cloud-computing/ "2 topics")
[Computers](http://www.win-vector.com/blog/tag/computers/ "2 topics")
[Data
Mining](http://www.win-vector.com/blog/tag/data-mining/ "5 topics")
[data
science](http://www.win-vector.com/blog/tag/data-science/ "11 topics")
[data science project
planning](http://www.win-vector.com/blog/tag/data-science-project-planning/ "4 topics")
[Dynamic
Programming](http://www.win-vector.com/blog/tag/dynamic-programming/ "5 topics")
[Finance](http://www.win-vector.com/blog/tag/finance/ "3 topics")
[fun](http://www.win-vector.com/blog/tag/fun/ "4 topics") [genetic
art](http://www.win-vector.com/blog/tag/genetic-art/ "2 topics")
[ggplot2](http://www.win-vector.com/blog/tag/ggplot2/ "5 topics")
[git](http://www.win-vector.com/blog/tag/git/ "4 topics")
[GLM](http://www.win-vector.com/blog/tag/glm/ "4 topics")
[Google](http://www.win-vector.com/blog/tag/google/ "3 topics")
[graphical
perception](http://www.win-vector.com/blog/tag/graphical-perception/ "3 topics")
[Hadoop](http://www.win-vector.com/blog/tag/hadoop/ "4 topics")
[Information
Taker](http://www.win-vector.com/blog/tag/information-taker/ "2 topics")
[linear
regression](http://www.win-vector.com/blog/tag/linear-regression/ "3 topics")
[log-likelihood](http://www.win-vector.com/blog/tag/log-likelihood/ "3 topics")
[Logistic
Regression](http://www.win-vector.com/blog/tag/logistic-regression/ "16 topics")
[Machine
Learning](http://www.win-vector.com/blog/tag/machine-learning/ "6 topics")
[Map Reduce](http://www.win-vector.com/blog/tag/map-reduce/ "4 topics")
[Markov
Chains](http://www.win-vector.com/blog/tag/markov-chains/ "4 topics")
[Mathematical Bedside
Reading](http://www.win-vector.com/blog/tag/mathematical-bedside-reading/ "8 topics")
[Mergers](http://www.win-vector.com/blog/tag/mergers/ "2 topics")
[modeling
trick](http://www.win-vector.com/blog/tag/modeling-trick/ "3 topics")
[Newton-Raphson](http://www.win-vector.com/blog/tag/newton-raphson/ "3 topics")
[Online
Advertising](http://www.win-vector.com/blog/tag/online-advertising/ "2 topics")
[Online
Libraries](http://www.win-vector.com/blog/tag/online-libraries/ "2 topics")
[Optimization](http://www.win-vector.com/blog/tag/optimization/ "3 topics")
[Practical Data
Science](http://www.win-vector.com/blog/tag/practical-data-science/ "5 topics")
[Practical Data Science with
R](http://www.win-vector.com/blog/tag/practical-data-science-with-r/ "10 topics")
[Pricing](http://www.win-vector.com/blog/tag/pricing/ "2 topics")
[R](http://www.win-vector.com/blog/tag/r/ "49 topics") [Random
Sampling](http://www.win-vector.com/blog/tag/random-sampling/ "4 topics")
[Regression](http://www.win-vector.com/blog/tag/regression/ "4 topics")
[Regularization](http://www.win-vector.com/blog/tag/regularization/ "3 topics")
[Sharpe
Ratio](http://www.win-vector.com/blog/tag/sharpe-ratio/ "2 topics")
[significance](http://www.win-vector.com/blog/tag/significance/ "8 topics")
[Statistics](http://www.win-vector.com/blog/tag/statistics/ "19 topics")
[Technical
Papers](http://www.win-vector.com/blog/tag/technical-papers/ "3 topics")
[Theorist](http://www.win-vector.com/blog/tag/theorist/ "3 topics")
[visualization](http://www.win-vector.com/blog/tag/visualization/ "3 topics")

### Comment Policy

All comments are held for moderation. Only comments that will be
interesting to other readers will be considered for posting. Comments
that are irrelevant, offensive or link-spam will be deleted. Also we do
use a mechanical comment spam filter, and would like to apologize in
advance for any comments that get lost to the filter.

### Categories

-   [Administrativia](http://www.win-vector.com/blog/category/administrativia/ "View all posts filed under Administrativia")
-   [Applications](http://www.win-vector.com/blog/category/applications/ "View all posts filed under Applications")
-   [art](http://www.win-vector.com/blog/category/art/ "View all posts filed under art")
-   [Coding](http://www.win-vector.com/blog/category/coding/ "View all posts filed under Coding")
-   [Computer
    Science](http://www.win-vector.com/blog/category/computer-science/ "View all posts filed under Computer Science")
-   [Computers](http://www.win-vector.com/blog/category/computers/ "View all posts filed under Computers")
-   [data
    science](http://www.win-vector.com/blog/category/data-science/ "View all posts filed under data science")
-   [Exciting
    Techniques](http://www.win-vector.com/blog/category/exciting-techniques/ "View all posts filed under Exciting Techniques")
-   [Expository
    Writing](http://www.win-vector.com/blog/category/expository-writing/ "View all posts filed under Expository Writing")
-   [Finance](http://www.win-vector.com/blog/category/finance/ "View all posts filed under Finance")
-   [History](http://www.win-vector.com/blog/category/history/ "View all posts filed under History")
-   [math
    programming](http://www.win-vector.com/blog/category/math-programming/ "View all posts filed under math programming")
-   [Mathematics](http://www.win-vector.com/blog/category/mathematics/ "View all posts filed under Mathematics")
-   [Opinion](http://www.win-vector.com/blog/category/opinion/ "View all posts filed under Opinion")
-   [Practical Data
    Science](http://www.win-vector.com/blog/category/practical-data-science/ "View all posts filed under Practical Data Science")
-   [Pragmatic Data
    Science](http://www.win-vector.com/blog/category/pragmatic-data-science/ "View all posts filed under Pragmatic Data Science")
-   [Pragmatic Machine
    Learning](http://www.win-vector.com/blog/category/pragmatic-machine-learning/ "View all posts filed under Pragmatic Machine Learning")
-   [Programming](http://www.win-vector.com/blog/category/programming/ "View all posts filed under Programming")
-   [Public Service
    Article](http://www.win-vector.com/blog/category/public-service-article/ "View all posts filed under Public Service Article")
-   [Quantitative
    Finance](http://www.win-vector.com/blog/category/quantitative-finance/ "View all posts filed under Quantitative Finance")
-   [Rants](http://www.win-vector.com/blog/category/rants/ "View all posts filed under Rants")
-   [Statistics](http://www.win-vector.com/blog/category/statistics/ "View all posts filed under Statistics")
-   [Statistics To English
    Translation](http://www.win-vector.com/blog/category/statistics-to-english-translation/ "View all posts filed under Statistics To English Translation")
-   [Tutorials](http://www.win-vector.com/blog/category/tutorials/ "View all posts filed under Tutorials")

### Blogroll

-   [Ephemera Experiments in Writing](http://exiw.wordpress.com)
-   [Follow WinVector LLC on
    Twitter!](https://twitter.com/WinVectorLLC "Follow WinVector LLC on Twitter!")
-   [GeneticArt.org](http://www.geneticart.org/ "Online Genetic Art Since 1994")
-   [Multo (Ghost)](http://multoghost.wordpress.com)
-   [mzlabs.com](http://www.mzlabs.com/ "John Mount and Nina Zumel papers")
-   [Nina Zumel .com](http://ninazumel.com)
-   [R-bloggers](http://www.r-bloggers.com "R news and tutorials")
-   [Statsblogs](http://www.statsblogs.com)
-   [The book: Practical Data Science with
    R](http://affiliate.manning.com/idevaffiliate.php?id=1273_360 "Our data science book.")
-   [Win-Vector
    LLC](http://www.win-vector.com/ "Win-Vector LLC main site")
-   [Win-Vector LLC on
    GitHub](https://github.com/WinVector "Experimental projects Win-Vector LLC has shared through GitHub")
-   [Win-Vector
    RSS](http://www.win-vector.com/blog/feed/ "Win-Vector RSS")

### Archives

-   [March 2014](http://www.win-vector.com/blog/2014/03/)
-   [February 2014](http://www.win-vector.com/blog/2014/02/)
-   [January 2014](http://www.win-vector.com/blog/2014/01/)
-   [December 2013](http://www.win-vector.com/blog/2013/12/)
-   [November 2013](http://www.win-vector.com/blog/2013/11/)
-   [October 2013](http://www.win-vector.com/blog/2013/10/)
-   [September 2013](http://www.win-vector.com/blog/2013/09/)
-   [August 2013](http://www.win-vector.com/blog/2013/08/)
-   [July 2013](http://www.win-vector.com/blog/2013/07/)
-   [June 2013](http://www.win-vector.com/blog/2013/06/)
-   [May 2013](http://www.win-vector.com/blog/2013/05/)
-   [April 2013](http://www.win-vector.com/blog/2013/04/)
-   [March 2013](http://www.win-vector.com/blog/2013/03/)
-   [February 2013](http://www.win-vector.com/blog/2013/02/)
-   [January 2013](http://www.win-vector.com/blog/2013/01/)
-   [December 2012](http://www.win-vector.com/blog/2012/12/)
-   [November 2012](http://www.win-vector.com/blog/2012/11/)
-   [October 2012](http://www.win-vector.com/blog/2012/10/)
-   [September 2012](http://www.win-vector.com/blog/2012/09/)
-   [August 2012](http://www.win-vector.com/blog/2012/08/)
-   [July 2012](http://www.win-vector.com/blog/2012/07/)
-   [June 2012](http://www.win-vector.com/blog/2012/06/)
-   [May 2012](http://www.win-vector.com/blog/2012/05/)
-   [April 2012](http://www.win-vector.com/blog/2012/04/)
-   [March 2012](http://www.win-vector.com/blog/2012/03/)
-   [February 2012](http://www.win-vector.com/blog/2012/02/)
-   [January 2012](http://www.win-vector.com/blog/2012/01/)
-   [December 2011](http://www.win-vector.com/blog/2011/12/)
-   [November 2011](http://www.win-vector.com/blog/2011/11/)
-   [October 2011](http://www.win-vector.com/blog/2011/10/)
-   [September 2011](http://www.win-vector.com/blog/2011/09/)
-   [August 2011](http://www.win-vector.com/blog/2011/08/)
-   [July 2011](http://www.win-vector.com/blog/2011/07/)
-   [June 2011](http://www.win-vector.com/blog/2011/06/)
-   [April 2011](http://www.win-vector.com/blog/2011/04/)
-   [March 2011](http://www.win-vector.com/blog/2011/03/)
-   [February 2011](http://www.win-vector.com/blog/2011/02/)
-   [January 2011](http://www.win-vector.com/blog/2011/01/)
-   [December 2010](http://www.win-vector.com/blog/2010/12/)
-   [November 2010](http://www.win-vector.com/blog/2010/11/)
-   [October 2010](http://www.win-vector.com/blog/2010/10/)
-   [September 2010](http://www.win-vector.com/blog/2010/09/)
-   [August 2010](http://www.win-vector.com/blog/2010/08/)
-   [July 2010](http://www.win-vector.com/blog/2010/07/)
-   [June 2010](http://www.win-vector.com/blog/2010/06/)
-   [May 2010](http://www.win-vector.com/blog/2010/05/)
-   [April 2010](http://www.win-vector.com/blog/2010/04/)
-   [March 2010](http://www.win-vector.com/blog/2010/03/)
-   [February 2010](http://www.win-vector.com/blog/2010/02/)
-   [January 2010](http://www.win-vector.com/blog/2010/01/)
-   [December 2009](http://www.win-vector.com/blog/2009/12/)
-   [November 2009](http://www.win-vector.com/blog/2009/11/)
-   [October 2009](http://www.win-vector.com/blog/2009/10/)
-   [September 2009](http://www.win-vector.com/blog/2009/09/)
-   [August 2009](http://www.win-vector.com/blog/2009/08/)
-   [July 2009](http://www.win-vector.com/blog/2009/07/)
-   [June 2009](http://www.win-vector.com/blog/2009/06/)
-   [May 2009](http://www.win-vector.com/blog/2009/05/)
-   [April 2009](http://www.win-vector.com/blog/2009/04/)
-   [March 2009](http://www.win-vector.com/blog/2009/03/)
-   [February 2009](http://www.win-vector.com/blog/2009/02/)
-   [January 2009](http://www.win-vector.com/blog/2009/01/)
-   [November 2008](http://www.win-vector.com/blog/2008/11/)
-   [October 2008](http://www.win-vector.com/blog/2008/10/)
-   [September 2008](http://www.win-vector.com/blog/2008/09/)
-   [August 2008](http://www.win-vector.com/blog/2008/08/)
-   [June 2008](http://www.win-vector.com/blog/2008/06/)
-   [May 2008](http://www.win-vector.com/blog/2008/05/)
-   [April 2008](http://www.win-vector.com/blog/2008/04/)
-   [March 2008](http://www.win-vector.com/blog/2008/03/)
-   [February 2008](http://www.win-vector.com/blog/2008/02/)
-   [October 2007](http://www.win-vector.com/blog/2007/10/)
-   [June 2007](http://www.win-vector.com/blog/2007/06/)

### Meta

-   [Log in](http://www.win-vector.com/blog/wp-login.php)

[Top](#) [WordPress](http://wordpress.org/)

Copyright © 2007-2014 Win-Vector Blog

Theme by [NeoEase](http://www.neoease.com/). Valid [XHTML
1.1](http://validator.w3.org/check?uri=referer) and [CSS
3](http://jigsaw.w3.org/css-validator/check/referer?profile=css3).

This markdown document has been converted from the html document located at:
http://www.win-vector.com/blog/2009/11/i-dont-think-that-means-what-you-think-it-means-statistics-to-english-translation-part-1-accuracy-measures/
