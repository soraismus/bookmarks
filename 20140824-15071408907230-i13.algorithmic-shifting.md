[Skip to content](#content)

[Gödel’s Lost Letter and P=NP](http://rjlipton.wordpress.com)

a personal view of the theory of computation
--------------------------------------------

-   [Home](http://rjlipton.wordpress.com)
-   [About P=NP and SAT](http://rjlipton.wordpress.com/about/)
-   [About Us](http://rjlipton.wordpress.com/about-me/)
-   [Conventional Wisdom and
    P=NP](http://rjlipton.wordpress.com/conventional-wisdom-and-pnp/)
-   [The Gödel Letter](http://rjlipton.wordpress.com/the-gdel-letter/)
-   [Cook’s Paper](http://rjlipton.wordpress.com/cooks-paper/)
-   [Thank You Page](http://rjlipton.wordpress.com/thank-you-page/)

Shifts In Algorithm Design
==========================

July 21, 2014

tags: [Algorithms](http://rjlipton.wordpress.com/tag/algorithms/),
[approximation](http://rjlipton.wordpress.com/tag/approximation/),
[Jennifer Chayes](http://rjlipton.wordpress.com/tag/jennifer-chayes/),
[randomness](http://rjlipton.wordpress.com/tag/randomness/)

by
[Pip](http://rjlipton.wordpress.com/author/dickken/ "View all posts by Pip")

\
 *How to find approximate page rank fast, among other things*\

[![Chayes](http://rjlipton.files.wordpress.com/2014/07/chayes.jpg?w=600)](https://rjlipton.files.wordpress.com/2014/07/chayes.jpg)

Jennifer Chayes is the current director of a research lab in
Cambridge—that is Cambridge Massachusetts—for a company called
Microsoft. She is famous for her own work in many areas of theory,
including phase transitions of complex systems. She is also famous for
her ability to create and manage research groups, which is a rare and
wonderful skill.

Today Ken and I wish to talk about how to be “shifty” in algorithm
design. There is nothing underhanded, but it’s a different playing field
from what we grew up with.

Ken first noted the paradigm shift in 1984 when hearing Leslie Valiant’s
British unveiling of his “Probably Approximately Correct” learning
theory at the Royal Society in London. Last year Leslie wrote a
[book](http://www.amazon.com/Probably-Approximately-Correct-Algorithms-Prospering/dp/0465032710)
with this title. That’s about learning, while here we want to discuss
the effect on algorithm design.

We illustrate this for a
[paper](http://www.tandfonline.com/doi/pdf/10.1080/15427951.2013.802752#.U81KsLH5dEA)
(ArXiv [version](http://arxiv.org/abs/1202.2771)) authored by Chayes and
Christian Borgs, Michael Brautbar, and Shang-Hua Teng. It is titled,
“Multi-Scale Matrix Sampling and Sublinear-Time PageRank Computation.”
Since PageRank is a vital application, they don’t want their algorithms
to be
[galactic](http://rjlipton.wordpress.com/2010/10/23/galactic-algorithms/).
They trade off by not having the algorithms “solve” the problems the way
we used to.

In The Good Old Days
--------------------

I, Dick, recall the “good old days of theory.” When I first started
working in theory—a sort of double meaning—I could only use
deterministic methods. I needed to get the exact answer, no
approximations. I had to solve the problem that I was given—no changing
the problem. Well sometimes I did that, but mostly I had to solve
**the** problem that was presented to me.

In the good old days of theory, we got a problem, we worked on it, and
sometimes we solved it. Nothing shifty, no changing the problem or
modifying the goal. I actually like today better than the “good old
days,” so I do not romanticize them.

One way to explain the notion of the good old days is to quote from a
Monty Python
[skit](http://www.phespirit.info/montypython/four_yorkshiremen.htm)
about four Yorkshiremen talking about the good old days. We pick it up a
few lines after one of them says, “I was happier then and I had nothin’.
We used to live in this tiny old house with great big holes in the
roof.” …

![{\\mathsf{FIRST \\
YORKSHIREMAN}}](http://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFIRST+%5C+YORKSHIREMAN%7D%7D&bg=ffffff&fg=000000&s=0 "{\mathsf{FIRST \ YORKSHIREMAN}}"):
You were lucky. We lived for three months in a paper bag in a septic
tank. We used to have to get up at six in the morning, clean the paper
bag, eat a crust of stale bread, go to work down t’ mill, fourteen hours
a day, week-in week-out, for sixpence a week, and when we got home our
Dad would thrash us to sleep wi’ his belt.

![{\\mathsf{SECOND \\
YORKSHIREMAN}}](http://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSECOND+%5C+YORKSHIREMAN%7D%7D&bg=ffffff&fg=000000&s=0 "{\mathsf{SECOND \ YORKSHIREMAN}}"):
Luxury. We used to have to get out of the lake at six o’clock in the
morning, clean the lake, eat a handful of ‘ot gravel, work twenty hour
day at mill for tuppence a month, come home, and Dad would thrash us to
sleep with a broken bottle, if we were lucky!

![{\\mathsf{THIRD \\
YORKSHIREMAN}}](http://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BTHIRD+%5C+YORKSHIREMAN%7D%7D&bg=ffffff&fg=000000&s=0 "{\mathsf{THIRD \ YORKSHIREMAN}}"):
Well, of course, we had it tough. We used to ‘ave to get up out of
shoebox at twelve o’clock at night and lick road clean wit’ tongue. We
had two bits of cold gravel, worked twenty-four hours a day at mill for
sixpence every four years, and when we got home our Dad would slice us
in two wit’ bread knife.

![{\\mathsf{FOURTH \\
YORKSHIREMAN}}](http://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFOURTH+%5C+YORKSHIREMAN%7D%7D&bg=ffffff&fg=000000&s=0 "{\mathsf{FOURTH \ YORKSHIREMAN}}"):
Right. I had to get up in the morning at ten o’clock at night half an
hour before I went to bed, drink a cup of sulphuric acid, work
twenty-nine hours a day down mill, and pay mill owner for permission to
come to work, and when we got home, our Dad and our mother would kill us
and dance about on our graves singing Hallelujah.

![{\\mathsf{FIRST \\
YORKSHIREMAN}}](http://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFIRST+%5C+YORKSHIREMAN%7D%7D&bg=ffffff&fg=000000&s=0 "{\mathsf{FIRST \ YORKSHIREMAN}}"):
And you try and tell the young people of today that ….. they won’t
believe you.

![{\\mathsf{ALL}}](http://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BALL%7D%7D&bg=ffffff&fg=000000&s=0 "{\mathsf{ALL}}"):
They won’t!

Today
-----

Those were the days. I did feel like I sometimes worked twenty-nine
hours a day, I was paid by Yale, but so little that perhaps it felt like
I paid them. Never had to drink a cup of sulphuric acid—but the
coffee—oh you get the idea.

Now today, in the 21st century, we have a better way to attack problems.
We change the problem, often to one that is more tractable and useful.
In many situations solving the exact problem is not really what a
practitioner needs. If computing X exactly requires too much time, then
it is useless to compute it. A perfect example is the weather: computing
tomorrow’s weather in a week’s time is clearly not very useful.

The brilliance of the current approach is that we can change the
problem. There are at least two major ways to do this:

![{\\bullet
}](http://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&bg=ffffff&fg=000000&s=0 "{\bullet }")
*Change the answer required*. Allow approximation, or allow a partial
answer. Do not insist on an exact answer.

![{ \\bullet
}](http://s0.wp.com/latex.php?latex=%7B+%5Cbullet+%7D&bg=ffffff&fg=000000&s=0 "{ \bullet }")
*Change the algorithmic method*. Allow algorithms that can be wrong, or
allow algorithms that use randomness. Do not insist that the algorithm
is a perfect deterministic one.

This is exactly what Chayes and her co-authors have done. So let’s take
a look at what they do in their paper.

PageRank
--------

In their paper they study
[PageRank](http://en.wikipedia.org/wiki/PageRank), which is the
definition and algorithm made famous by Google. It gives a way to rank
webpages in response to a query that supplements criteria from the query
itself. An old query-specific criterion was the number of matches to a
keyword in the query. Rather than rank solely by this count, PageRank
emphasizes a general page score. The score is sometimes interpreted as a
measure of “popularity” or “authority,” leading to the following
circular-seeming definitions:

![{\\bullet}](http://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&bg=ffffff&fg=000000&s=0 "{\bullet}")
A webpage is popular if it has a healthy number of links from popular
pages.

![{\\bullet}](http://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&bg=ffffff&fg=000000&s=0 "{\bullet}")
A webpage is authoritative if it is well cited, especially by other
authoritative pages.

What the PageRank score actually denotes mathematically is the
likelihood that a person randomly traversing links will arrive at any
particular page. This includes a frequency
![{\\alpha}](http://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&bg=ffffff&fg=000000&s=0 "{\alpha}")
with which the person will stop clicking, do something healthier like
ride a bicycle, and start again on a “random” webpage.

The situation can be modeled by the classic random walk on a directed
graph. We have a graph
![{G}](http://s0.wp.com/latex.php?latex=%7BG%7D&bg=ffffff&fg=000000&s=0 "{G}")
on
![{N}](http://s0.wp.com/latex.php?latex=%7BN%7D&bg=ffffff&fg=000000&s=0 "{N}")
nodes and an ![{N \\times
N}](http://s0.wp.com/latex.php?latex=%7BN+%5Ctimes+N%7D&bg=ffffff&fg=000000&s=0 "{N \times N}")
matrix
![{M}](http://s0.wp.com/latex.php?latex=%7BM%7D&bg=ffffff&fg=000000&s=0 "{M}")
that is **row-stochastic**, meaning the entries in each row are
non-negative and sum to
![{1}](http://s0.wp.com/latex.php?latex=%7B1%7D&bg=ffffff&fg=000000&s=0 "{1}").
Given that the web-walker is at node
![{i}](http://s0.wp.com/latex.php?latex=%7Bi%7D&bg=ffffff&fg=000000&s=0 "{i}"),
the entry
![{M[i,j]}](http://s0.wp.com/latex.php?latex=%7BM%5Bi%2Cj%5D%7D&bg=ffffff&fg=000000&s=0 "{M[i,j]}")
is the probability of going next to node
![{j}](http://s0.wp.com/latex.php?latex=%7Bj%7D&bg=ffffff&fg=000000&s=0 "{j}").
If node
![{i}](http://s0.wp.com/latex.php?latex=%7Bi%7D&bg=ffffff&fg=000000&s=0 "{i}")
has *out-*degree
![{b}](http://s0.wp.com/latex.php?latex=%7Bb%7D&bg=ffffff&fg=000000&s=0 "{b}"),
then

![\\displaystyle M[i,j] = \\frac{\\alpha}{N} + \\begin{cases} (1 -
\\alpha)\\frac{1}{b} & \\text{if\~} i \\text{\~links to\~} j\\\\ 0 &
\\text{otherwise.}\\end{cases}
](http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M%5Bi%2Cj%5D+%3D+%5Cfrac%7B%5Calpha%7D%7BN%7D+%2B+%5Cbegin%7Bcases%7D+%281+-+%5Calpha%29%5Cfrac%7B1%7D%7Bb%7D+%26+%5Ctext%7Bif%7E%7D+i+%5Ctext%7B%7Elinks+to%7E%7D+j%5C%5C+0+%26+%5Ctext%7Botherwise.%7D%5Cend%7Bcases%7D+&bg=ffffff&fg=000000&s=0 "\displaystyle  M[i,j] = \frac{\alpha}{N} + \begin{cases} (1 - \alpha)\frac{1}{b} & \text{if~} i \text{~links to~} j\\ 0 & \text{otherwise.}\end{cases} ")

We can tweak this e.g. by
[modeling](http://hal.archives-ouvertes.fr/docs/00/66/83/39/PDF/2p370.pdf)
the user hitting the “Back” button on the browser, or jumping to another
browser tab, or using a search engine. We could also set
![{\\alpha}](http://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&bg=ffffff&fg=000000&s=0 "{\alpha}")
higher in case page
![{i}](http://s0.wp.com/latex.php?latex=%7Bi%7D&bg=ffffff&fg=000000&s=0 "{i}")
has few or no outgoing links. We still get an
![{M}](http://s0.wp.com/latex.php?latex=%7BM%7D&bg=ffffff&fg=000000&s=0 "{M}"),
and since the use of
![{\\alpha}](http://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&bg=ffffff&fg=000000&s=0 "{\alpha}")
effectively makes the graph strongly connected and averts certain
pathologies, we get a beautiful conclusion from random-walk theory:
There is a unique **stationary distribution**
![{P}](http://s0.wp.com/latex.php?latex=%7BP%7D&bg=ffffff&fg=000000&s=0 "{P}"),
which is the unique left-eigenvector for the largest eigenvalue, which
as normalized above is
![{1}](http://s0.wp.com/latex.php?latex=%7B1%7D&bg=ffffff&fg=000000&s=0 "{1}"):

![\\displaystyle P M = P.
](http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P+M+%3D+P.+&bg=ffffff&fg=000000&s=0 "\displaystyle  P M = P. ")

Then the PageRank of node
![{i}](http://s0.wp.com/latex.php?latex=%7Bi%7D&bg=ffffff&fg=000000&s=0 "{i}")
is
![{P(i)}](http://s0.wp.com/latex.php?latex=%7BP%28i%29%7D&bg=ffffff&fg=000000&s=0 "{P(i)}").
It is remarkable that this simple, salient idea from the good old days
works so well. A further fact from the theory (and use of
![{\\alpha}](http://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&bg=ffffff&fg=000000&s=0 "{\alpha}"))
is that if you start at *any* node, in the long run you will find
yourself on page
![{i}](http://s0.wp.com/latex.php?latex=%7Bi%7D&bg=ffffff&fg=000000&s=0 "{i}")
with frequency
![{P(i)}](http://s0.wp.com/latex.php?latex=%7BP%28i%29%7D&bg=ffffff&fg=000000&s=0 "{P(i)}").
Here is Wikipedia’s graphical example:

\

[![rank](http://rjlipton.files.wordpress.com/2014/07/rank.png?w=300&h=241)](https://rjlipton.files.wordpress.com/2014/07/rank.png)

\
 The issue is: *how* to compute
![{P(i)}](http://s0.wp.com/latex.php?latex=%7BP%28i%29%7D&bg=ffffff&fg=000000&s=0 "{P(i)}")?
In the good old days this was a trivial problem—just use linear algebra.
But now the issue is that
![{N}](http://s0.wp.com/latex.php?latex=%7BN%7D&bg=ffffff&fg=000000&s=0 "{N}")
is really big, let alone ![{N \\times
N}](http://s0.wp.com/latex.php?latex=%7BN+%5Ctimes+N%7D&bg=ffffff&fg=000000&s=0 "{N \times N}")
being unspeakably big. The
![{N}](http://s0.wp.com/latex.php?latex=%7BN%7D&bg=ffffff&fg=000000&s=0 "{N}")
is too big even to get an approximation via the “further fact,” that is
by simulating a random walk on the whole graph, and classical
sparse-matrix methods might only help a little. This is where Chayes and
company change the game: let us care about computing
![{P(i)}](http://s0.wp.com/latex.php?latex=%7BP%28i%29%7D&bg=ffffff&fg=000000&s=0 "{P(i)}")
only for some
![{i}](http://s0.wp.com/latex.php?latex=%7Bi%7D&bg=ffffff&fg=000000&s=0 "{i}")‘s,
and even then, let us be content with fairly rough approximation.

The Shifted Problems
--------------------

The approximation to PageRank is called SignificantPageRank. The paper
gives a randomized algorithm that solves the following problem.

> Let us be given a graph. Then, given a target threshold
> ![{\\Delta}](http://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&bg=e8e8e8&fg=000000&s=0 "{\Delta}")
> and an approximation factor ![{c \>
> 1}](http://s0.wp.com/latex.php?latex=%7Bc+%3E+1%7D&bg=e8e8e8&fg=000000&s=0 "{c > 1}"),
> we are asked to output a set
> ![{S}](http://s0.wp.com/latex.php?latex=%7BS%7D&bg=e8e8e8&fg=000000&s=0 "{S}")
> of nodes such that with high probability,
> ![{S}](http://s0.wp.com/latex.php?latex=%7BS%7D&bg=e8e8e8&fg=000000&s=0 "{S}")
> contains all nodes of PageRank at least
> ![{\\Delta}](http://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&bg=e8e8e8&fg=000000&s=0 "{\Delta}"),
> and no node of PageRank smaller than
> ![{\\frac{1}{c}\\Delta}](http://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7Bc%7D%5CDelta%7D&bg=e8e8e8&fg=000000&s=0 "{\frac{1}{c}\Delta}").

This is a perfect example of the shift. The algorithm is random, and the
problem is to find not the nodes with a given PageRank, but those that
are not too far away.

The nifty point is that the algorithm can tolerate fuzzing the matrix
![{M}](http://s0.wp.com/latex.php?latex=%7BM%7D&bg=ffffff&fg=000000&s=0 "{M}"),
in a manner called SARA for “sparse and approximate row access”:

> Given
> ![{i}](http://s0.wp.com/latex.php?latex=%7Bi%7D&bg=e8e8e8&fg=000000&s=0 "{i}")
> and
> ![{\\epsilon}](http://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&bg=e8e8e8&fg=000000&s=0 "{\epsilon}"),
> return a set
> ![{S}](http://s0.wp.com/latex.php?latex=%7BS%7D&bg=e8e8e8&fg=000000&s=0 "{S}")
> of
> ![{O(1/\\epsilon)}](http://s0.wp.com/latex.php?latex=%7BO%281%2F%5Cepsilon%29%7D&bg=e8e8e8&fg=000000&s=0 "{O(1/\epsilon)}")
> columns
> ![{j}](http://s0.wp.com/latex.php?latex=%7Bj%7D&bg=e8e8e8&fg=000000&s=0 "{j}")
> and values
> ![{p\_j}](http://s0.wp.com/latex.php?latex=%7Bp_j%7D&bg=e8e8e8&fg=000000&s=0 "{p_j}")
> such that for all
> ![{j}](http://s0.wp.com/latex.php?latex=%7Bj%7D&bg=e8e8e8&fg=000000&s=0 "{j}"):
>
> -   ![{j \\in S \\implies |p\_j - M[i,j]| \\leq
>     \\epsilon}](http://s0.wp.com/latex.php?latex=%7Bj+%5Cin+S+%5Cimplies+%7Cp_j+-+M%5Bi%2Cj%5D%7C+%5Cleq+%5Cepsilon%7D&bg=e8e8e8&fg=000000&s=0 "{j \in S \implies |p_j - M[i,j]| \leq \epsilon}"),
>     and
> -   ![{j \\notin S \\implies M[i,j] \\leq
>     \\epsilon}](http://s0.wp.com/latex.php?latex=%7Bj+%5Cnotin+S+%5Cimplies+M%5Bi%2Cj%5D+%5Cleq+%5Cepsilon%7D&bg=e8e8e8&fg=000000&s=0 "{j \notin S \implies M[i,j] \leq \epsilon}").

It is important to use this for different values of
![{\\epsilon}](http://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&bg=ffffff&fg=000000&s=0 "{\epsilon}").
The cost of a query ![{(i,\\epsilon) \\rightarrow
S}](http://s0.wp.com/latex.php?latex=%7B%28i%2C%5Cepsilon%29+%5Crightarrow+S%7D&bg=ffffff&fg=000000&s=0 "{(i,\epsilon) \rightarrow S}")
is ![{\\Theta(|S|) =
O(1/\\epsilon)}](http://s0.wp.com/latex.php?latex=%7B%5CTheta%28%7CS%7C%29+%3D+O%281%2F%5Cepsilon%29%7D&bg=ffffff&fg=000000&s=0 "{\Theta(|S|) = O(1/\epsilon)}").

If we picture
“![{N}](http://s0.wp.com/latex.php?latex=%7BN%7D&bg=ffffff&fg=000000&s=0 "{N}")”
as “exponential” and take ![{\\epsilon =
1/\\mathsf{poly}(n)}](http://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3D+1%2F%5Cmathsf%7Bpoly%7D%28n%29%7D&bg=ffffff&fg=000000&s=0 "{\epsilon = 1/\mathsf{poly}(n)}")
where ![{n = \\log
N}](http://s0.wp.com/latex.php?latex=%7Bn+%3D+%5Clog+N%7D&bg=ffffff&fg=000000&s=0 "{n = \log N}"),
then this becomes an approximative version of
![{M}](http://s0.wp.com/latex.php?latex=%7BM%7D&bg=ffffff&fg=000000&s=0 "{M}")
being **succinct**, which we just
[talked](http://rjlipton.wordpress.com/2014/07/16/constructive-sets/)
about. In this scaling of
![{\\epsilon}](http://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&bg=ffffff&fg=000000&s=0 "{\epsilon}")
we are effectively limiting to a
![{\\mathsf{poly}(n)}](http://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bpoly%7D%28n%29%7D&bg=ffffff&fg=000000&s=0 "{\mathsf{poly}(n)}")
**local** portion
![{S}](http://s0.wp.com/latex.php?latex=%7BS%7D&bg=ffffff&fg=000000&s=0 "{S}")
of the graph around node
![{i}](http://s0.wp.com/latex.php?latex=%7Bi%7D&bg=ffffff&fg=000000&s=0 "{i}").
Since we also have ![{\\frac{\\alpha}{N} \\ll
\\epsilon}](http://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B%5Calpha%7D%7BN%7D+%5Cll+%5Cepsilon%7D&bg=ffffff&fg=000000&s=0 "{\frac{\alpha}{N} \ll \epsilon}"),
under SARA entries outside
![{S}](http://s0.wp.com/latex.php?latex=%7BS%7D&bg=ffffff&fg=000000&s=0 "{S}")
would become effectively zero, so that the chance of “teleporting”
outside
![{S}](http://s0.wp.com/latex.php?latex=%7BS%7D&bg=ffffff&fg=000000&s=0 "{S}")
on the whole would be regarded as negligible. In fact the paper also
researches the case where each Web user always starts afresh at a “home
node”
![{u}](http://s0.wp.com/latex.php?latex=%7Bu%7D&bg=ffffff&fg=000000&s=0 "{u}")
in that portion, making ![{M[i,u] =
\\alpha}](http://s0.wp.com/latex.php?latex=%7BM%5Bi%2Cu%5D+%3D+%5Calpha%7D&bg=ffffff&fg=000000&s=0 "{M[i,u] = \alpha}")
just for that user. Then the
![{\\alpha}](http://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&bg=ffffff&fg=000000&s=0 "{\alpha}")-related
probability is not negligible, and the resulting user-dependent estimate
is called PersonalizedPageRank.

The problem they need to solve for SignificantPageRank then becomes
“SignificantColumnSums”:

> Given
> ![{M}](http://s0.wp.com/latex.php?latex=%7BM%7D&bg=e8e8e8&fg=000000&s=0 "{M}")
> and
> ![{\\Delta,c}](http://s0.wp.com/latex.php?latex=%7B%5CDelta%2Cc%7D&bg=e8e8e8&fg=000000&s=0 "{\Delta,c}")
> as above, find a set
> ![{S}](http://s0.wp.com/latex.php?latex=%7BS%7D&bg=e8e8e8&fg=000000&s=0 "{S}")
> of columns such that for all columns
> ![{j}](http://s0.wp.com/latex.php?latex=%7Bj%7D&bg=e8e8e8&fg=000000&s=0 "{j}"):
>
> -   ![{\\sum\_i M[i,j] \\geq \\Delta \\implies j \\in
>     S}](http://s0.wp.com/latex.php?latex=%7B%5Csum_i+M%5Bi%2Cj%5D+%5Cgeq+%5CDelta+%5Cimplies+j+%5Cin+S%7D&bg=e8e8e8&fg=000000&s=0 "{\sum_i M[i,j] \geq \Delta \implies j \in S}");
> -   ![{\\sum\_i M[i,j] \\leq \\frac{1}{c}\\Delta \\implies j \\notin
>     S}](http://s0.wp.com/latex.php?latex=%7B%5Csum_i+M%5Bi%2Cj%5D+%5Cleq+%5Cfrac%7B1%7D%7Bc%7D%5CDelta+%5Cimplies+j+%5Cnotin+S%7D&bg=e8e8e8&fg=000000&s=0 "{\sum_i M[i,j] \leq \frac{1}{c}\Delta \implies j \notin S}").

An even simpler problem which they use as a stepping-stone is
“VectorSum”:

> Given a
> length-![{N}](http://s0.wp.com/latex.php?latex=%7BN%7D&bg=e8e8e8&fg=000000&s=0 "{N}")
> vector
> ![{P}](http://s0.wp.com/latex.php?latex=%7BP%7D&bg=e8e8e8&fg=000000&s=0 "{P}")
> with entries in
> ![{[0,1]}](http://s0.wp.com/latex.php?latex=%7B%5B0%2C1%5D%7D&bg=e8e8e8&fg=000000&s=0 "{[0,1]}"),
> and ![{1 \\leq \\Delta \\leq
> N}](http://s0.wp.com/latex.php?latex=%7B1+%5Cleq+%5CDelta+%5Cleq+N%7D&bg=e8e8e8&fg=000000&s=0 "{1 \leq \Delta \leq N}")
> and ![{c \>
> 1}](http://s0.wp.com/latex.php?latex=%7Bc+%3E+1%7D&bg=e8e8e8&fg=000000&s=0 "{c > 1}"):
>
> -   output **yes** if ![{{}\\text{\~}\\sum\_i P(i) \\geq
>     \\Delta}](http://s0.wp.com/latex.php?latex=%7B%7B%7D%5Ctext%7B%7E%7D%5Csum_i+P%28i%29+%5Cgeq+%5CDelta%7D&bg=e8e8e8&fg=000000&s=0 "{{}\text{~}\sum_i P(i) \geq \Delta}");
> -   output **no** if ![{{}\\text{\~}\\sum\_i P(i) \\leq
>     \\frac{\\Delta}{c}}](http://s0.wp.com/latex.php?latex=%7B%7B%7D%5Ctext%7B%7E%7D%5Csum_i+P%28i%29+%5Cleq+%5Cfrac%7B%5CDelta%7D%7Bc%7D%7D&bg=e8e8e8&fg=000000&s=0 "{{}\text{~}\sum_i P(i) \leq \frac{\Delta}{c}}"),
>     don’t-care otherwise.

The goal is always to avoid looking at all
![{N}](http://s0.wp.com/latex.php?latex=%7BN%7D&bg=ffffff&fg=000000&s=0 "{N}")
nodes or entries, but only an ![{N\^{1 -
\\gamma}}](http://s0.wp.com/latex.php?latex=%7BN%5E%7B1+-+%5Cgamma%7D%7D&bg=ffffff&fg=000000&s=0 "{N^{1 - \gamma}}")
or so portion of them, where ![{\\gamma \>
0}](http://s0.wp.com/latex.php?latex=%7B%5Cgamma+%3E+0%7D&bg=ffffff&fg=000000&s=0 "{\gamma > 0}").
Thus the problem shift is necessitated by
![{N}](http://s0.wp.com/latex.php?latex=%7BN%7D&bg=ffffff&fg=000000&s=0 "{N}")
being huge. This isn’t my good-old-days idea of solving a problem, but
can be called
“![{(\\Delta,c)}](http://s0.wp.com/latex.php?latex=%7B%28%5CDelta%2Cc%29%7D&bg=ffffff&fg=000000&s=0 "{(\Delta,c)}")-solving”
it.

Multi-Level Sampling and Results
--------------------------------

Ken and I are interested because these are similar to problems we have
been encountering in our quest for more cases where quantum algorithms
can be simulated in classical randomized polynomial time. Thus any new
ideas are appreciated, and what catches our eye is a *multi-level*
approximation scheme that exploits the requirement of SARA to work for
different
![{\\epsilon}](http://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&bg=ffffff&fg=000000&s=0 "{\epsilon}").
The situations are different, but we hope to adapt them.

The situation for VectorSum is that a probe ![{(i,\\epsilon)
\\rightarrow
P(i)}](http://s0.wp.com/latex.php?latex=%7B%28i%2C%5Cepsilon%29+%5Crightarrow+P%28i%29%7D&bg=ffffff&fg=000000&s=0 "{(i,\epsilon) \rightarrow P(i)}")
still costs order-of
![{1/\\epsilon}](http://s0.wp.com/latex.php?latex=%7B1%2F%5Cepsilon%7D&bg=ffffff&fg=000000&s=0 "{1/\epsilon}"),
and returns
![{0}](http://s0.wp.com/latex.php?latex=%7B0%7D&bg=ffffff&fg=000000&s=0 "{0}")
unless ![{P(i) \\geq
\\epsilon}](http://s0.wp.com/latex.php?latex=%7BP%28i%29+%5Cgeq+%5Cepsilon%7D&bg=ffffff&fg=000000&s=0 "{P(i) \geq \epsilon}").
A simple-minded use of a set
![{S}](http://s0.wp.com/latex.php?latex=%7BS%7D&bg=ffffff&fg=000000&s=0 "{S}")
of random probes for the same
![{\\epsilon}](http://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&bg=ffffff&fg=000000&s=0 "{\epsilon}")
would yield the estimate

![\\displaystyle \\frac{N}{|S|} \\sum\_{i \\in S: P(i) \\geq \\epsilon}
P(i).
](http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7BN%7D%7B%7CS%7C%7D+%5Csum_%7Bi+%5Cin+S%3A+P%28i%29+%5Cgeq+%5Cepsilon%7D+P%28i%29.+&bg=ffffff&fg=000000&s=0 "\displaystyle  \frac{N}{|S|} \sum_{i \in S: P(i) \geq \epsilon} P(i). ")

The resulting error has order
![{N\\epsilon}](http://s0.wp.com/latex.php?latex=%7BN%5Cepsilon%7D&bg=ffffff&fg=000000&s=0 "{N\epsilon}"),
so we need ![{\\epsilon \\approx
\\frac{\\Delta}{N}}](http://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%5Capprox+%5Cfrac%7B%5CDelta%7D%7BN%7D%7D&bg=ffffff&fg=000000&s=0 "{\epsilon \approx \frac{\Delta}{N}}")
which is rather demanding. Indeed the total cost would have order
![{\\frac{|S|N}{\\Delta}}](http://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B%7CS%7CN%7D%7B%5CDelta%7D%7D&bg=ffffff&fg=000000&s=0 "{\frac{|S|N}{\Delta}}"),
where
![{S}](http://s0.wp.com/latex.php?latex=%7BS%7D&bg=ffffff&fg=000000&s=0 "{S}")
needs to be so large as to kill any hope of making the cost ![{N\^{1 -
\\gamma}}](http://s0.wp.com/latex.php?latex=%7BN%5E%7B1+-+%5Cgamma%7D%7D&bg=ffffff&fg=000000&s=0 "{N^{1 - \gamma}}")
or even
![{o(N)}](http://s0.wp.com/latex.php?latex=%7Bo%28N%29%7D&bg=ffffff&fg=000000&s=0 "{o(N)}").
In the pivotal case where ![{\\sum\_i P(i) =
\\Delta}](http://s0.wp.com/latex.php?latex=%7B%5Csum_i+P%28i%29+%3D+%5CDelta%7D&bg=ffffff&fg=000000&s=0 "{\sum_i P(i) = \Delta}"),
we would need ![{|S| \\approx
\\frac{N}{\\Delta}}](http://s0.wp.com/latex.php?latex=%7B%7CS%7C+%5Capprox+%5Cfrac%7BN%7D%7B%5CDelta%7D%7D&bg=ffffff&fg=000000&s=0 "{|S| \approx \frac{N}{\Delta}}"),
incurring cost on the order of
![{(\\frac{N}{\\Delta})\^2}](http://s0.wp.com/latex.php?latex=%7B%28%5Cfrac%7BN%7D%7B%5CDelta%7D%29%5E2%7D&bg=ffffff&fg=000000&s=0 "{(\frac{N}{\Delta})^2}").

However, they show that by using a different precision ![{\\epsilon\_t
\\approx
\\frac{t}{|S|}}](http://s0.wp.com/latex.php?latex=%7B%5Cepsilon_t+%5Capprox+%5Cfrac%7Bt%7D%7B%7CS%7C%7D%7D&bg=ffffff&fg=000000&s=0 "{\epsilon_t \approx \frac{t}{|S|}}")
for each random probe, they can get acceptable error with a reasonably
small number of probes. The case ![{t =
1}](http://s0.wp.com/latex.php?latex=%7Bt+%3D+1%7D&bg=ffffff&fg=000000&s=0 "{t = 1}")
where we have ![{\\epsilon \\approx \\frac{1}{|S|} =
\\frac{\\Delta}{N}}](http://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%5Capprox+%5Cfrac%7B1%7D%7B%7CS%7C%7D+%3D+%5Cfrac%7B%5CDelta%7D%7BN%7D%7D&bg=ffffff&fg=000000&s=0 "{\epsilon \approx \frac{1}{|S|} = \frac{\Delta}{N}}")
occurs only once, so its
![{\\frac{N}{\\Delta}}](http://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B%5CDelta%7D%7D&bg=ffffff&fg=000000&s=0 "{\frac{N}{\Delta}}")
cost can be tolerated. Other probes have smaller cost, and while their
precisions are looser, the aggregate precision on the estimate becomes
good enough for the following result:

> **Theorem 1** Given
> ![{P,c,\\Delta}](http://s0.wp.com/latex.php?latex=%7BP%2Cc%2C%5CDelta%7D&bg=e8e8e8&fg=000000&s=0 "{P,c,\Delta}")
> as above and ![{\\delta \>
> 0}](http://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E+0%7D&bg=e8e8e8&fg=000000&s=0 "{\delta > 0}"),
> VectorSum can be
> ![{(\\Delta,c)}](http://s0.wp.com/latex.php?latex=%7B%28%5CDelta%2Cc%29%7D&bg=e8e8e8&fg=000000&s=0 "{(\Delta,c)}")-solved
> with probability at least ![{1 -
> \\delta}](http://s0.wp.com/latex.php?latex=%7B1+-+%5Cdelta%7D&bg=e8e8e8&fg=000000&s=0 "{1 - \delta}")
> and cost
>
> ![\\displaystyle
> O\\left(\\frac{N}{\\Delta}\\left(\\frac{1}{c-1}\\right)\^2
> \\log\\left(\\frac{N}{\\Delta(c-1)}\\right)\\log\\left(\\frac{2}{\\delta}\\right)\\right).
> ](http://s0.wp.com/latex.php?latex=%5Cdisplaystyle++O%5Cleft%28%5Cfrac%7BN%7D%7B%5CDelta%7D%5Cleft%28%5Cfrac%7B1%7D%7Bc-1%7D%5Cright%29%5E2+%5Clog%5Cleft%28%5Cfrac%7BN%7D%7B%5CDelta%28c-1%29%7D%5Cright%29%5Clog%5Cleft%28%5Cfrac%7B2%7D%7B%5Cdelta%7D%5Cright%29%5Cright%29.+&bg=e8e8e8&fg=000000&s=0 "\displaystyle  O\left(\frac{N}{\Delta}\left(\frac{1}{c-1}\right)^2 \log\left(\frac{N}{\Delta(c-1)}\right)\log\left(\frac{2}{\delta}\right)\right). ")
>
Well in the good old days before LaTeX we wouldn’t even have been easily
able to write such a formula with a typewriter, let alone prove it. But
it is certainly better than
![{(\\frac{N}{\\Delta})\^2}](http://s0.wp.com/latex.php?latex=%7B%28%5Cfrac%7BN%7D%7B%5CDelta%7D%29%5E2%7D&bg=ffffff&fg=000000&s=0 "{(\frac{N}{\Delta})^2}"),
and allows taking ![{\\Delta =
N\^{\\gamma}}](http://s0.wp.com/latex.php?latex=%7B%5CDelta+%3D+N%5E%7B%5Cgamma%7D%7D&bg=ffffff&fg=000000&s=0 "{\Delta = N^{\gamma}}")
to meet the goal of runtime ![{\\tilde{O}(N\^{1 -
\\gamma})}](http://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BO%7D%28N%5E%7B1+-+%5Cgamma%7D%29%7D&bg=ffffff&fg=000000&s=0 "{\tilde{O}(N^{1 - \gamma})}").
As usual, for the details on SignificantColumnSums and the application
problems, see the [paper](http://arxiv.org/abs/1202.2771).

Open Problems
-------------

Do you miss the good old days? Or do you like the current approaches?
What shifts, what new types of changing the goals, might we see in the
future? For clearly today will one day be the “good old days.”

[changed qualifier on "certain pathologies", may as well footnote here
that the "Back" button creates a Markov Chain *with memory*; changed
intro to say British unveiling" of PAC learning.]

[About these ads](http://en.wordpress.com/about-these-ads/)

### Share this:

-   [Reddit](http://rjlipton.wordpress.com/2014/07/21/shifts-in-algorithm-design/?share=reddit "Click to share on Reddit")
-   [StumbleUpon](http://rjlipton.wordpress.com/2014/07/21/shifts-in-algorithm-design/?share=stumbleupon "Click to share on StumbleUpon")
-   [Facebook](http://rjlipton.wordpress.com/2014/07/21/shifts-in-algorithm-design/?share=facebook "Share on Facebook")
-   

### Like this:

Like Loading...

### *Related*

from → [All Posts](http://rjlipton.wordpress.com/category/all-posts/),
[History](http://rjlipton.wordpress.com/category/all-posts/history/),
[Ideas](http://rjlipton.wordpress.com/category/all-posts/ideas/),
[Oldies](http://rjlipton.wordpress.com/category/all-posts/oldies/),
[Results](http://rjlipton.wordpress.com/category/all-posts/results/)

[← Constructive
Sets](http://rjlipton.wordpress.com/2014/07/16/constructive-sets/)

[An Old Galactic Result
→](http://rjlipton.wordpress.com/2014/07/25/an-old-galactic-result/)

6 Comments [leave one →](#respond "Leave One")

1.  ![image](http://2.gravatar.com/avatar/b7026b87c51690329e9ef5b74928bbfb?s=60&d=identicon&r=G)

    [vznvzn](http://vzn1.wordpress.com)
    [permalink](http://rjlipton.wordpress.com/2014/07/21/shifts-in-algorithm-design/#comment-53959)

    July 22, 2014 10:38 am

    have been looking into a thread somewhat similar to this. spielman
    came up with a major improvement on fast algorithms for finding
    graph clusters based on random walks of graphs eg highlighted by
    Klarreich here: [simons institute, Network Solutions:\
     A new breed of ultrafast computer algorithms offers computer
    scientists a novel tool to probe the structure of large
    networks.](http://www.simonsfoundation.org/mathematics-and-physical-science/network-solutions/)
    this meshes with some other theory looking at bounds on random
    walks, some of which can be computed via pagerank theory. eg this
    high voted but unanswered question [Mixing properties of random
    walks on
    graphs.](http://cstheory.stackexchange.com/questions/25124/mixing-properties-of-random-walks-on-graphs)
    tricky stuff, anyone else, any ideas? yeah randomized algorithms are
    a whole new way of thinking and seem to be quite fundamental to
    theory in deep ways that are still yet to be uncovered. although one
    could observe that they seem to have very close/deep connections
    with that old concept, nondeterminism.

    [Reply](/2014/07/21/shifts-in-algorithm-design/?replytocom=53959#respond)

2.  ![image](http://1.gravatar.com/avatar/d903871906732a6a67db619748499edd?s=60&d=identicon&r=G)

    [M. Vidyasagar](http://www.utdallas.edu/~m.vidyasagar)
    [permalink](http://rjlipton.wordpress.com/2014/07/21/shifts-in-algorithm-design/#comment-53984)

    July 23, 2014 3:59 pm

    Dear Profs. Lipton and Regan,

    A wonderful column as usual. Prof. Valiant’s seminal paper “A theory
    of the learnable” was published in the Communications of the ACM in
    1984. But according to the web site of The Royal Society, Prof.
    Valiant was elected as a Fellow only in 1991! So the recollection of
    Prof. Regan “in 1984 when hearing Leslie Valiant’s inaugural talk on
    “Probably Approximately Correct” learning at the Royal Society in
    London” appears to be “probably approximately correct”! :)

    Don’t ask me why, but I was once invited to explain PAC learning
    theory to a group of Indian metallurgists. I explained that a PAC
    algorithm is one that “more or less works most of the time,” and
    they seemed happy with that.

    I shall certainly look up the paper by Chayes et al.

    Keep up the good work!

    [Reply](/2014/07/21/shifts-in-algorithm-design/?replytocom=53984#respond)

    -   ![image](http://1.gravatar.com/avatar/7f5bfd8236587a9173030f92f9f08244?s=60&d=identicon&r=G)

        [KWRegan](http://www.cse.buffalo.edu/~regan/)
        [permalink](http://rjlipton.wordpress.com/2014/07/21/shifts-in-algorithm-design/#comment-53995)

        July 24, 2014 8:08 am

        Thanks for the nice comment. By my recollection it was a lecture
        held in the Royal Society building at Carleton House Terrace.
        Possibly it was in a building of the University of London, as
        part of a workshop that had Royal Society sponsorship. I know we
        went down from Oxford most specifically to hear it—it was more
        of an “event” and “unveiling” than if Les were giving an invited
        talk at U. London or Oxford or Warwick, say.

        [Reply](/2014/07/21/shifts-in-algorithm-design/?replytocom=53995#respond)

        -   ![image](http://1.gravatar.com/avatar/d903871906732a6a67db619748499edd?s=60&d=identicon&r=G)

            [M. Vidyasagar](http://www.utdallas.edu/~m.vidyasagar)
            [permalink](http://rjlipton.wordpress.com/2014/07/21/shifts-in-algorithm-design/#comment-54008)

            July 24, 2014 11:38 pm

            Dear Prof. Regan,

            The premises of The Royal Society at Carleton House Terrace
            are often rented out to host meetings that are unconnected
            with the Fellowship. So it is quite possible that in 1984
            you heard Prof. Valiant talk about PAC learning at Carleton
            House Terrace. My only comment was that it cannot have been
            his “inaugural talk” upon being elected as an FRS.

            Again, I do really enjoy this blog. I just wish I had the
            time and energy (not to mention the talent) to keep up with
            the wealth of information being provided).

            Kind regards.

        -   ![image](http://1.gravatar.com/avatar/7f5bfd8236587a9173030f92f9f08244?s=60&d=identicon&r=G)

            [KWRegan](http://www.cse.buffalo.edu/~regan/)
            [permalink](http://rjlipton.wordpress.com/2014/07/21/shifts-in-algorithm-design/#comment-54015)

            July 25, 2014 10:07 am

            I meant “inaugural talk” about PAC learning—as I said, it
            was a special event, and it was “at the Royal Society” with
            their aegis. I knew he was elected in 1991; I didn’t think
            what I wrote would be taken your way.

3.  ![image](http://2.gravatar.com/avatar/5b50488388953868f19a726833f91970?s=60&d=identicon&r=G)

    [g.t.](http://www.cocoon-bobbin-oil.com)
    [permalink](http://rjlipton.wordpress.com/2014/07/21/shifts-in-algorithm-design/#comment-54010)

    July 25, 2014 4:29 am

    Thanks for this post. Seems like there’s always something new I
    learn even after being in the field for 25 years

    [Reply](/2014/07/21/shifts-in-algorithm-design/?replytocom=54010#respond)

### Leave a Reply [Cancel reply](/2014/07/21/shifts-in-algorithm-design/#respond)

Enter your comment here...

Fill in your details below or click an icon to log in:

-   [](#comment-form-guest "Guest")
-   [](#comment-form-load-service:WordPress.com "WordPress.com")
-   [](#comment-form-load-service:Twitter "Twitter")
-   [](#comment-form-load-service:Facebook "Facebook")
-   

[![Gravatar](http://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&d=identicon&forcedefault=y&r=G)](https://gravatar.com/site/signup/)

Email (required) (Address never made public)

Name (required)

Website

![WordPress.com
Logo](http://s2.wp.com/wp-content/mu-plugins/highlander-comments/images/wplogo.png?m=1391188133g)

**** You are commenting using your WordPress.com account. ( [Log
Out](javascript:HighlanderComments.doExternalLogout(%20'wordpress'%20);)
/ [Change](#) )

![Twitter
picture](http://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&d=identicon&forcedefault=y&r=G)

**** You are commenting using your Twitter account. ( [Log
Out](javascript:HighlanderComments.doExternalLogout(%20'twitter'%20);) /
[Change](#) )

![Facebook
photo](http://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&d=identicon&forcedefault=y&r=G)

**** You are commenting using your Facebook account. ( [Log
Out](javascript:HighlanderComments.doExternalLogout(%20'facebook'%20);)
/ [Change](#) )

![Google+
photo](http://1.gravatar.com/avatar/ad516503a11cd5ca435acc9bb6523536?s=25&d=identicon&forcedefault=y&r=G)

**** You are commenting using your Google+ account. ( [Log
Out](javascript:HighlanderComments.doExternalLogout(%20'googleplus'%20);)
/ [Change](#) )

[Cancel](javascript:HighlanderComments.cancelExternalWindow();)

Connecting to %s

Notify me of follow-up comments via email.

-   Subscribe to Gödel’s Lost Letter
    --------------------------------

    [![image](http://faq.files.wordpress.com/2006/11/a28.png)](http://rjlipton.wordpress.com/feed)

-   -   Our Book
    --------

    [![image](http://rjlipton.files.wordpress.com/2014/02/our-book.jpg?w=115&h=173)](http://www.amazon.com/People-Problems-Proofs-Essays-Gödels/dp/3642414214/ref=sr_1_2?s=books&ie=UTF8&qid=1393085404&sr=1-2)

-   Recent Posts
    ------------

    -   [Why Is 290
        Special?](http://rjlipton.wordpress.com/2014/08/23/why-is-290-special/)
    -   [The Derivative Of A
        Number](http://rjlipton.wordpress.com/2014/08/19/the-derivative-of-a-number/)
    -   [The 3SUM Assumption Is
        Wrong?](http://rjlipton.wordpress.com/2014/08/16/the-3sum-assumption-is-wrong-2/)
    -   [Our Three Body
        Problem](http://rjlipton.wordpress.com/2014/08/13/our-three-body-problem/)
    -   [Laplace’s
        Demon](http://rjlipton.wordpress.com/2014/08/08/laplaces-demon/)
    -   [Diagonalization Without
        Sets](http://rjlipton.wordpress.com/2014/08/03/diagonalization-without-sets/)
    -   [The Cantor-Bernstein-Schröder
        Theorem](http://rjlipton.wordpress.com/2014/07/31/the-cantor-bernstein-schroder-theorem/)
    -   [An Old Galactic
        Result](http://rjlipton.wordpress.com/2014/07/25/an-old-galactic-result/)
    -   [Shifts In Algorithm
        Design](http://rjlipton.wordpress.com/2014/07/21/shifts-in-algorithm-design/)
    -   [Constructive
        Sets](http://rjlipton.wordpress.com/2014/07/16/constructive-sets/)
    -   [High School
        Theorems](http://rjlipton.wordpress.com/2014/07/10/high-school-theorems/)
    -   [Do Random Walks Help Avoid
        Fireworks?](http://rjlipton.wordpress.com/2014/07/04/do-random-walks-help-avoid-fireworks/)
    -   [Remembering Ann
        Yasuhara](http://rjlipton.wordpress.com/2014/07/01/remembering-ann-yasuhara/)
    -   [A Pretty
        Identity](http://rjlipton.wordpress.com/2014/06/29/a-pretty-identity/)
    -   [Counting Edge Colorings Is
        Hard](http://rjlipton.wordpress.com/2014/06/23/counting-edge-colorings-is-hard/)

-   Top Posts
    ---------

    -   [Shifts In Algorithm
        Design](http://rjlipton.wordpress.com/2014/07/21/shifts-in-algorithm-design/)
    -   [Why Is 290
        Special?](http://rjlipton.wordpress.com/2014/08/23/why-is-290-special/)
    -   [The Derivative Of A
        Number](http://rjlipton.wordpress.com/2014/08/19/the-derivative-of-a-number/)
    -   [Galactic
        Algorithms](http://rjlipton.wordpress.com/2010/10/23/galactic-algorithms/)
    -   [Our Three Body
        Problem](http://rjlipton.wordpress.com/2014/08/13/our-three-body-problem/)
    -   [The Gödel
        Letter](http://rjlipton.wordpress.com/the-gdel-letter/)
    -   [Laplace's
        Demon](http://rjlipton.wordpress.com/2014/08/08/laplaces-demon/)
    -   [The 3SUM Assumption Is
        Wrong?](http://rjlipton.wordpress.com/2014/08/16/the-3sum-assumption-is-wrong-2/)
    -   [About Us](http://rjlipton.wordpress.com/about-me/)
    -   [About P=NP and SAT](http://rjlipton.wordpress.com/about/)

-   Recent Comments
    ---------------

      ---------------------------------------------------------------------------------------------------------------------------------- ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      [](http://www.xenosystems.net/chaos-patch-24/)                                                                                     [Outside in - Involve…](http://www.xenosystems.net/chaos-patch-24/) on [Judging A Book By Its Cov…](http://rjlipton.wordpress.com/2013/12/06/judging-a-book-by-its-coverage/#comment-55122)
      [![image](http://1.gravatar.com/avatar/a23b9df554f5ee2e60fdc13645e4c50d?s=48&d=identicon&r=G)](http://www.ma.huji.ac.il/~kalai/)   [Gil Kalai](http://www.ma.huji.ac.il/~kalai/) on [Quantum Supremacy or Classical…](http://rjlipton.wordpress.com/2012/10/03/quantum-supremacy-or-classical-control/#comment-55117)
      [![image](http://1.gravatar.com/avatar/a23b9df554f5ee2e60fdc13645e4c50d?s=48&d=identicon&r=G)](http://www.ma.huji.ac.il/~kalai/)   [Gil Kalai](http://www.ma.huji.ac.il/~kalai/) on [Quantum Supremacy or Classical…](http://rjlipton.wordpress.com/2012/10/03/quantum-supremacy-or-classical-control/#comment-55116)
      [![image](http://2.gravatar.com/avatar/53463a46070b974244107e96ca869e5d?s=48&d=identicon&r=G)](http://inquiryintoinquiry.com/)     [Jon Awbrey](http://inquiryintoinquiry.com/) on [The Derivative Of A Numbe…](http://rjlipton.wordpress.com/2014/08/19/the-derivative-of-a-number/#comment-55109)
      [](http://qandasys.info/probabilistic-randomized-algorithms-before-modern-computer-science-appeared-2/)                            [Probabilistic (rando…](http://qandasys.info/probabilistic-randomized-algorithms-before-modern-computer-science-appeared-2/) on [Rabin Flips a Coin](http://rjlipton.wordpress.com/2009/03/01/rabin-flips-a-coin/#comment-55103)
      [![image](http://2.gravatar.com/avatar/53463a46070b974244107e96ca869e5d?s=48&d=identicon&r=G)](http://inquiryintoinquiry.com/)     [Jon Awbrey](http://inquiryintoinquiry.com/) on [Why Is 290 Special?](http://rjlipton.wordpress.com/2014/08/23/why-is-290-special/#comment-55102)
      [](http://rjlipton.wordpress.com/2014/08/23/why-is-290-special/)                                                                   [Why Is 290 Special?…](http://rjlipton.wordpress.com/2014/08/23/why-is-290-special/) on [Surely You Are Joking?](http://rjlipton.wordpress.com/2013/07/14/surely-you-are-joking/#comment-55101)
      [](http://rjlipton.wordpress.com/2014/08/23/why-is-290-special/)                                                                   [Why Is 290 Special?…](http://rjlipton.wordpress.com/2014/08/23/why-is-290-special/) on [Computational Topology](http://rjlipton.wordpress.com/2012/02/12/computational-topology/#comment-55100)
      [](http://rjlipton.wordpress.com/2014/08/23/why-is-290-special/)                                                                   [Why Is 290 Special?…](http://rjlipton.wordpress.com/2014/08/23/why-is-290-special/) on [Rabin Meets Lagrange](http://rjlipton.wordpress.com/2014/03/23/rabin-meets-lagrange/#comment-55099)
      [](http://rjlipton.wordpress.com/2014/08/23/why-is-290-special/)                                                                   [Why Is 290 Special?…](http://rjlipton.wordpress.com/2014/08/23/why-is-290-special/) on [A Pretty Identity](http://rjlipton.wordpress.com/2014/06/29/a-pretty-identity/#comment-55098)
      ![image](http://0.gravatar.com/avatar/f9612f7daf6a45f3e96114fbdbfc9950?s=48&d=identicon&r=G)                                       Craig on [Our Three Body Problem](http://rjlipton.wordpress.com/2014/08/13/our-three-body-problem/#comment-55065)
      [![image](http://2.gravatar.com/avatar/24ee673de88d3b72ddf2772a8e49008d?s=48&d=identicon&r=G)](http://gowers.wordpress.com)        [gowers](http://gowers.wordpress.com) on [Our Three Body Problem](http://rjlipton.wordpress.com/2014/08/13/our-three-body-problem/#comment-55063)
      ![image](http://0.gravatar.com/avatar/608593e422377f6092d703bb648fe139?s=48&d=identicon&r=G)                                       Justin Pees on [A New Million Dollar Priz…](http://rjlipton.wordpress.com/2010/07/21/a-new-million-dollar-prize/#comment-55050)
      ![image](http://2.gravatar.com/avatar/2cb3bb864cd69ada61d7d245aff62a09?s=48&d=identicon&r=G)                                       Daniel on [Laplace’s Demon](http://rjlipton.wordpress.com/2014/08/08/laplaces-demon/#comment-55042)
      ![image](http://2.gravatar.com/avatar/58803d9127b739fffe18647f3a5522b8?s=48&d=identicon&r=G)                                       Anonymous on [Laplace’s Demon](http://rjlipton.wordpress.com/2014/08/08/laplaces-demon/#comment-55039)
      ---------------------------------------------------------------------------------------------------------------------------------- ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

-   Blogroll
    --------

    -   [Adam Bohn](http://yabm.wordpress.com/)
    -   [Algorithmic Game
        Theory](http://agtb.wordpress.com/ "Noam Nisan blog")
    -   [Ars Mathematica](http://www.arsmathematica.net)
    -   [Computational Complexity](http://weblog.fortnow.com/)
    -   [Equilibrium](http://blog.eqnets.com/)
    -   [Gil Kalai](http://gilkalai.wordpress.com/)
    -   [Gowers’s Weblog](http://gowers.wordpress.com)
    -   [London Number Theory
        blog](http://londonnumbertheory.wordpress.com)
    -   [Luca Trevisan](http://lucatrevisan.wordpress.com/)
    -   [Martin
        Schwarz](http://martinschwarz.wordpress.com/ "Quantum Complexity Theory")
    -   [math less
        traveled](http://mathlesstraveled.com/about-me/#comment-4341)
    -   [mathbabe](http://mathbabe.org)
    -   [Matt Baker](http://mattbakerblog.wordpress.com)
    -   [Michael Mitzenmacher](http://mybiasedcoin.blogspot.com/)
    -   [Michael Nielsen](http://michaelnielsen.org/blog/)
    -   [Microarray Blog](http://microarray.wordpress.com)
    -   [My Biased Coin](http://mybiasedcoin.blogspot.com)
    -   [Oddly Shaped Pegs](http://adamdsmith.wordpress.com)
    -   [Process Algebra Diary](http://processalgebra.blogspot.com/)
    -   [Random bits](http://jonkatz.wordpress.com)
    -   [Rigorous Trivialities](http://rigtriv.wordpress.com)
    -   [Scott Aaronson](http://www.scottaaronson.com/blog/)
    -   [Secret Blogging Seminar](http://sbseminar.wordpress.com)
    -   [Secret Blogging Seminar](http://sbseminar.wordpress.com)
    -   [Speedup](http://speedupblogger.wordpress.com)
    -   [Suresh Venkatasubramanian](http://geomblog.blogspot.com/)
    -   [Tanya Khovanova](http://blog.tanyakhovanova.com)
    -   [tcs math](http://tcsmath.wordpress.com)
    -   [Terence Tao](http://terrytao.wordpress.com/)
    -   [The Algorithmic Lens](http://cstheory.wordpress.com)
    -   [the polylogblog](http://polylogblog.wordpress.com)
    -   [The Unapologetic
        Mathematician](http://unapologetic.wordpress.com)
    -   [Turing Invisible Hand](http://agtb.wordpress.com)
    -   [WWC](http://richde.wordpress.com)
    -   [XOR\\’s Hammer](http://xorshammer.com)

-   Archives
    --------

    Select Month August 2014 July 2014 June 2014 May 2014 April 2014
    March 2014 February 2014 January 2014 December 2013 November 2013
    October 2013 September 2013 August 2013 July 2013 June 2013 May 2013
    April 2013 March 2013 February 2013 January 2013 December 2012
    November 2012 October 2012 September 2012 August 2012 July 2012 June
    2012 May 2012 April 2012 March 2012 February 2012 January 2012
    December 2011 November 2011 October 2011 September 2011 August 2011
    July 2011 June 2011 May 2011 April 2011 March 2011 February 2011
    January 2011 December 2010 November 2010 October 2010 September 2010
    August 2010 July 2010 June 2010 May 2010 April 2010 March 2010
    February 2010 January 2010 December 2009 November 2009 October 2009
    September 2009 August 2009 July 2009 June 2009 May 2009 April 2009
    March 2009 February 2009

-   Sitemeter
    ---------

    [![Site
    Meter](http://sm6.sitemeter.com/meter.asp?site=sm6godel)](http://sm6.sitemeter.com/stats.asp?site=sm6godel)

[Create a free website or blog at
WordPress.com](http://wordpress.com/?ref=footer_website).

[The Vigilance
Theme](https://wordpress.com/themes/vigilance/ "Learn more about this theme").

[Follow](javascript:void(0))

### Follow “Gödel's Lost Letter and P=NP”

Get every new post delivered to your Inbox.

Join 1,655 other followers

[Powered by WordPress.com](https://wordpress.com/?ref=lof)

%d bloggers like this:

![image](http://pixel.wp.com/b.gif?v=noscript)

This markdown document has been converted from the html document located at:
http://rjlipton.wordpress.com/2014/07/21/shifts-in-algorithm-design/
